{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c31f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd15136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238276a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "#display(HTML(\"<style>.prompt { display:none !important; }</style>\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2ddfc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "\n",
    "    def __init__(self, sizes, activations, Loss, epochs, metric, learning_rate):\n",
    "        self.weights =[np.random.randn(sizes[i],sizes[i-1]) for i in range(1, len(sizes))]\n",
    "        self.biases =  [np.zeros((1, sizes[i])) for i in range(1, len(sizes))]\n",
    "        self.activations = activations\n",
    "        self.Loss = Loss\n",
    "        self.epochs = epochs\n",
    "        self.metric = metric\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        self.activated_layers = [x]\n",
    "        for w,b, act in zip(self.weights, self.biases, self.activations):\n",
    "            activation = act.activate(np.dot(x, w.T) + b)\n",
    "            self.activated_layers.append(activation)\n",
    "            x = activation\n",
    "            \n",
    "            \n",
    "    def backpropagate(self, y):\n",
    "        #Input: activated_layers\n",
    "        #output: Container Gradient dE/dw \n",
    "        #Initialize\n",
    "        sigmas_box = []\n",
    "        sigma_prime_box = []\n",
    "    \n",
    "       #Backprop the error ()\n",
    "        #1. Compute output layer sigma\n",
    "        loss_grad = self.Loss.loss_gradient(self.activated_layers[-1], y)\n",
    "        output_sigma = self.activations[-1].output_layer_sigma(loss_grad, self.activated_layers[-1])\n",
    "        sigmas_box = [output_sigma]\n",
    "        #Sigmas of the rest of layers...\n",
    "        for w,a,o_layer in zip(self.weights[::-1], self.activations[:-1][::-1],self.activated_layers[:-1][::-1]) :\n",
    "            sigmas_box.append(np.dot(sigmas_box[-1], w) * a.sigma_prime(o_layer))\n",
    "       \n",
    "        #Reverse sigma_box    \n",
    "        sigmas_box.reverse()\n",
    "        #Biases update\n",
    "        self.grad_biases = sigmas_box\n",
    "        #Gradient (dE/dw):\n",
    "        self.gradients = []\n",
    "        for a, s in zip(self.activated_layers[:-1], sigmas_box):\n",
    "            self.gradients.append(np.dot(s.T, a))\n",
    "        #Nota: al hacerse la multiplicacion de todos los inputs a la vez\n",
    "        #Igual se mantiene el shape de cada weight pero mientras más\n",
    "        #Inputs más grandes salen los valores de cada componente de la matriz\n",
    "        #Por eso después se divide cada weight por el total de inputs (mean)\n",
    "        # print(\"Gradients shapes:\")\n",
    "        # for g in gradients:\n",
    "        #     print(g.shape)\n",
    "       \n",
    "\n",
    "    def weight_update(self):\n",
    "        for w,gw, b, gb in zip(self.weights, self.gradients, self.biases, self.grad_biases):\n",
    "            w -= (self.learning_rate / len(X))* gw\n",
    "            b -= (self.learning_rate / len(gb))* np.sum(gb, axis= 0)\n",
    "\n",
    "        return self.weights, self.biases\n",
    "        \n",
    "    \n",
    "    def predict(self, X,y):\n",
    "            self.forward(X)\n",
    "            self.prediction = self.activated_layers[-1]\n",
    "            #Compute the accuracy\n",
    "            acc = self.metric.get_accuracy(self.prediction, y)\n",
    "            print(\"Predictive accuracy:\", acc)\n",
    "\n",
    "\n",
    "            \n",
    "    def SGD(self, X,y,x_test, y_test, minibatch_size):\n",
    "        \"\"\"Vectorized version\"\"\"\n",
    "        print(\"SGD Training......\")\n",
    "        for e in range(1, self.epochs + 1):\n",
    "            #tomar dataset y generar minibatches box\n",
    "            minibatches = self.minibatch_generator(X,y, minibatch_size)\n",
    "            Losses = []\n",
    "            Accuracies = []\n",
    "            for mb in minibatches:\n",
    "                nabla_w, nabla_b = [], [] #box para ir guardando los dC/dw y dC/db de cada ejemplo\n",
    "                input = mb[0]\n",
    "                y_true = np.array(mb[1]).astype(int)\n",
    "                #Dar un forward pass \n",
    "                #print(\"Minibatch input shape:\", input.shape)\n",
    "                #print(\"Minibatch y_true shape:\", y_true.shape)\n",
    "                #print(\"Bias\", self.biases[0])\n",
    "\n",
    "                \n",
    "                self.forward(input)\n",
    "                #Calcular el error\n",
    "                error = self.Loss.forward_loss(self.activated_layers[-1], y_true)\n",
    "                #Guardar el error y accuracy\n",
    "                Losses.append(error)\n",
    "                Accuracies.append(self.metric.get_accuracy(self.activated_layers[-1], y_true))\n",
    "\n",
    "\n",
    "                #Obtener los dC/dw y dC/db del minibatch usando backprop\n",
    "                self.backpropagate(y_true)\n",
    "                delta_nw = self.gradients #dC/dw\n",
    "                delta_nb = self.grad_biases #dC/db\n",
    "                self.weights = [w - (self.learning_rate/ len(mb)) * dw for w,dw in zip(self.weights, delta_nw)]\n",
    "                self.biases = [b - (self.learning_rate/ len(mb)) * np.sum(db, axis = 0) for b, db in zip(self.biases, delta_nb)]\n",
    "            \n",
    "            #Reporte de error epoch...\n",
    "            if (e % 100 == 0 ) or (e == self.epochs):\n",
    "                print(\"Average Error epoch {0}: {1}---Average Accuracy: {2}\".format(e, np.mean(Losses), np.mean(Accuracies)))\n",
    "                print(\"Accuracy in test set:\", self.evaluate_test(x_test, y_test))\n",
    "                   \n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    \n",
    "            \n",
    "    def Momentum(self, X,y,x_test, y_test, minibatch_size, beta = 0.9):\n",
    "        \"\"\"Vectorized version\"\"\"\n",
    "        print(\"SGD Training......\")\n",
    "        for e in range(1, self.epochs + 1):\n",
    "            #tomar dataset y generar minibatches box\n",
    "            minibatches = self.minibatch_generator(X,y, minibatch_size)\n",
    "            Losses = []\n",
    "            Accuracies = []\n",
    "            #Velocities initialization\n",
    "            Vdw = [np.zeros(w.shape) for w in self.weights]\n",
    "            Vdb = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "            for mb in minibatches:\n",
    "                nabla_w, nabla_b = [], [] #box para ir guardando los dC/dw y dC/db de cada ejemplo\n",
    "                input = mb[0]\n",
    "                y_true = np.array(mb[1]).astype(int)\n",
    "                #Dar un forward pass \n",
    "                #print(\"Minibatch input shape:\", input.shape)\n",
    "                #print(\"Minibatch y_true shape:\", y_true.shape)\n",
    "                #print(\"Bias\", self.biases[0])\n",
    "                \n",
    "                self.forward(input)\n",
    "                #Calcular el error\n",
    "                #error = np.mean(self.Loss.forward_loss(self.activated_layers[-1], y_true))\n",
    "                error = self.Loss.forward_loss(self.activated_layers[-1], y_true)\n",
    "\n",
    "                #Guardar el error y accuracy\n",
    "                Losses.append(error)\n",
    "                Accuracies.append(self.metric.get_accuracy(self.activated_layers[-1], y_true))\n",
    "\n",
    "                #Obtener los dC/dw y dC/db del minibatch usando backprop\n",
    "                self.backpropagate(y_true)\n",
    "                delta_nw = self.gradients #dC/dw\n",
    "                delta_nb = self.grad_biases #dC/db\n",
    "                \n",
    "                #Compute the exp moving averages (velocities)\n",
    "                Vdw = [beta * vw + (1 - beta) * dnw for vw, dnw in zip(Vdw, delta_nw)]\n",
    "                Vdb = [beta * vb + (1 - beta) * dnb for vb, dnb in zip(Vdb, delta_nb)]\n",
    "                \n",
    "                #Update weights and biases using the Velocities\n",
    "                \n",
    "                self.weights = [w - (self.learning_rate/ len(mb)) * dw for w,dw in zip(self.weights, Vdw)]\n",
    "                self.biases = [b - (self.learning_rate/ len(mb)) * np.sum(db, axis = 0) for b, db in zip(self.biases, Vdb)]\n",
    "            \n",
    "            #Reporte de error epoch...\n",
    "            if (e % 100 == 0 ) or (e == self.epochs):\n",
    "                print(\"Average Error epoch {0}: {1}---Average Accuracy: {2}\".format(e, np.mean(Losses), np.mean(Accuracies)))\n",
    "                print(\"Accuracy in test set:\", self.evaluate_test(x_test, y_test))\n",
    "                   \n",
    "        print(\"Training complete!\") \n",
    "\n",
    "    def minibatch_generator(self, X,y, batch_size):\n",
    "        dataset = list(zip(X,np.array(y)))\n",
    "        np.random.shuffle(dataset)\n",
    "        minibatches = [(X[i:i+batch_size,:], y[i:i+batch_size]) for\n",
    "                        i in range(0, len(y), batch_size)]\n",
    "\n",
    "        #si minibatch final es mas chico que el batch size se le mete desde\n",
    "        #atras inputs hasta completar el tamaño batch size\n",
    "        if len(minibatches[-1][0]) < batch_size:\n",
    "            #print(\"Len minibatches -1:\", len(minibatches[-1][0]))\n",
    "            minibatches[-1] = (X[-batch_size:,:], y[-batch_size:])\n",
    "            \n",
    "        return minibatches\n",
    "    \n",
    "    def evaluate_test(self, x_test, y_test):\n",
    "        \"\"\"Evaluates the model on the test set\n",
    "        input: x_test, y_test\n",
    "        output: accuracy\"\"\"\n",
    "        #Forward pass---obtain prediction y_pred\n",
    "        self.forward(x_test)\n",
    "        #Evaluate prediction with accuracy\n",
    "        acc_test = self.metric.get_accuracy(self.activated_layers[-1], y_test)\n",
    "        #Return accuracy\n",
    "        return acc_test\n",
    "\n",
    "        \n",
    " \n",
    "class Relu():\n",
    "    def activate(self, x):\n",
    "        self.output = np.maximum(0,x)\n",
    "        return self.output\n",
    "    \n",
    "    def sigma_prime(self, x):\n",
    "        return 1. * (x > 0)\n",
    "\n",
    "\n",
    "class Sigmoid():\n",
    "    def activate(self, x):\n",
    "        #np.exp - (x - np.max(x, axis = 1, keepdims= True))\n",
    "        x = np.clip(x, 1e-7, 1 - 1e-7)\n",
    "        self.output = 1 / (1+ np.exp (- (x - np.max(x, axis = 1, keepdims= True))))\n",
    "        #self.output = 1 / (1+ np.exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def output_layer_sigma(self, loss_gradients, x):\n",
    "        \"\"\"en realidad calcula todo el sigma de una vez como dC/da * sigma_prime\n",
    "        dC/da = loss_gradient\"\"\"\n",
    "        \n",
    "        self.output_sigma = loss_gradients * self.sigma_prime(x)\n",
    "        return self.output_sigma\n",
    "    \n",
    "    def sigma_prime(self, x):\n",
    "        return x * (1-x)\n",
    "\n",
    "class Softmax():\n",
    "    def activate(self, x):\n",
    "        #Get unnormalized probs\n",
    "        exp_values = np.exp(x - np.max(x, axis = 1, keepdims= True))\n",
    "        #Get normalized probs\n",
    "        self.output = exp_values / np.sum(exp_values, axis= 1, keepdims= True)\n",
    "        return self.output\n",
    "    \n",
    "    def output_layer_sigma(self, loss_gradients, out_activations):\n",
    "        \"\"\"Dado que es complejo multplicar el jacobiano de cada input por\n",
    "        #su loss_gradient por que el jac es una matrix, se hace aca todo directo y se saca \n",
    "        #el output layer sigma = dE/dsigma.dsigma/dz\"\"\"\n",
    "        #Se crea un contenedor donde irá el output_sigma de cada input\n",
    "        #del tamaño del loss_gradient (dinputs)\n",
    "        self.output_sigma = np.empty_like(loss_gradients)\n",
    "\n",
    "        #Tomo uno a uno los Loss_gradientes de cada input y cada\n",
    "        #softmax activation de la output layer para hacer uno a uno los\n",
    "        #output_sigmas...\n",
    "        for index, (single_act, single_loss_grad) in enumerate(zip(out_activations, loss_gradients)):\n",
    "            single_act = single_act.reshape(-1,1)\n",
    "            #Calculate jacobian matrix (sigma_prime of softmax)\n",
    "            jacobian_matrix = np.diagflat(single_act) - np.dot(single_act, single_act.T)\n",
    "            self.output_sigma[index] = np.dot(jacobian_matrix, single_loss_grad)\n",
    "        return self.output_sigma\n",
    "\n",
    "         \n",
    "\n",
    "    \n",
    "##Loss Units\n",
    "class MSE():\n",
    "    \n",
    "    #Forward\n",
    "    def forward_loss(self, y_pred, y_true):\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        labels = len(y_pred[0])                  \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        #return  np.sum((y_pred- y_true)**2, axis=1) / len(y_pred)\n",
    "        return ((y_pred- y_true)**2).mean()\n",
    "        \n",
    "    #Derivative\n",
    "    def loss_gradient(self, y_pred, y_true): #dE/dact\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        labels = len(y_pred[0])                  \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        self.dinputs = (2/len(y_pred)) * (y_pred - y_true)\n",
    "        return self.dinputs\n",
    "    \n",
    "    \n",
    "class CategoricalCrossEntropyLoss():\n",
    "    def forward_loss(self, y_pred, y_true):\n",
    "         #entrega el vector de negative losses de cada sample\n",
    "         y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7) #recorta para evitar logs mulas\n",
    "         if len(y_true.shape) == 1: #si el y_true viene en un solo vector de escalares\n",
    "             #extraigo el valor que tiene el indice indicado en el y_true\n",
    "             #correspondiente\n",
    "             correct_confidences = y_pred[range(len(y_pred)), y_true]\n",
    "        \n",
    "         if len(y_true.shape) == 2: #matrix\n",
    "             #lo mismo pero multiplique y sume para obtener el valor\n",
    "             #que tiene el indice indicado por el y_true (el resto se hace zero\n",
    "             #al multiplicar)\n",
    "             correct_confidences = np.sum( y_pred * y_true, axis = 1)\n",
    "        \n",
    "         negative_loss_likehoods = -np.log(correct_confidences)\n",
    "\n",
    "         return negative_loss_likehoods\n",
    "    \n",
    "    def loss_gradient(self, dvalues, y_true): #dE/dact\n",
    "        # Number of samples\n",
    "        dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "        return self.dinputs\n",
    "\n",
    "\n",
    "\n",
    "class Accuracy():\n",
    "#gets the accuracy of the training stage\n",
    "    def get_accuracy(self, y_pred, y_true):\n",
    "        #saca el indice donde esta el valor mas grande\n",
    "        predictions = np.argmax(y_pred, axis= 1)\n",
    "\n",
    "        #y_true en formato escalares\n",
    "        if len(y_true.shape) == 1:\n",
    "            accuracy = np.mean(predictions == y_true)\n",
    "        #matrix\n",
    "        elif len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis= 1)\n",
    "            accuracy = np.mean(predictions == y_true) #promedia coincidencias de valor de indice\n",
    "\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f429c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"mnist_train.csv\", delimiter= \",\")\n",
    "# X = train.iloc[:, 1:]\n",
    "# y = train.iloc[:, 0]\n",
    "\n",
    "# #Loading test set\n",
    "# test = pd.read_csv(\"mnist_test.csv\", delimiter= \",\")\n",
    "# x_test = test.iloc[:, 1:]\n",
    "# y_test = test.iloc[:, 0]\n",
    "\n",
    "# # scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# # X = scaler.transform(X)\n",
    "# # test_X = scaler.transform( test_X )\n",
    "\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform( X )\n",
    "# x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0841124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes2 = [784,30, 10]\n",
    "# EPOCHS = 3000\n",
    "# #sizes2 = [4, 5,  3]\n",
    "# net = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "#             epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.9)\n",
    "# #net = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "#             #epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.07)\n",
    "# #net.train(X,y)\n",
    "\n",
    "# #net.SGD(X , np.array(y), x_test, y_test, minibatch_size = 10)\n",
    "# #net.SGD(X[:10000] , y[:10000], x_test, y_test, minibatch_size = 10)\n",
    "# #net.Momentum(X[:10000] , y[:10000], x_test, y_test, minibatch_size = 10, beta = 0.9)\n",
    "# #net.SGD(X[:1000] , y[:1000], x_test, y_test, minibatch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "457cef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "#             epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "# net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "#             epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bc776a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"mnist_train.csv\", delimiter= \",\")\n",
    "# X = train.iloc[:, 1:]\n",
    "# y = train.iloc[:, 0]\n",
    "\n",
    "# #Loading test set\n",
    "# test = pd.read_csv(\"mnist_test.csv\", delimiter= \",\")\n",
    "# x_test = test.iloc[:, 1:]\n",
    "# y_test = test.iloc[:, 0]\n",
    "\n",
    "# # scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# # X = scaler.transform(X)\n",
    "# # test_X = scaler.transform( test_X )\n",
    "\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform( X )\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "# sizes2 = [784,30, 10]\n",
    "# EPOCHS = 50\n",
    "\n",
    "# net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "#             epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "# net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "#             epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b3464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data \n",
    "y_iris= iris.target\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_iris)\n",
    "\n",
    "X_scaled = scaler.transform(X_iris)\n",
    "\n",
    "sizes = [4, 10, 3]\n",
    "EPOCHS = 50\n",
    "net3 = Dense(sizes, activations = [Relu(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "                 epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "398f3cd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-72c192a228a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "net3.predict(X_scaled[:5], y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9c585571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"mnist_train.csv\", delimiter= \",\")\n",
    "X = train.iloc[:, 1:]\n",
    "y = train.iloc[:, 0]\n",
    "\n",
    "#Loading test set\n",
    "test = pd.read_csv(\"mnist_test.csv\", delimiter= \",\")\n",
    "x_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# X = scaler.transform(X)\n",
    "# test_X = scaler.transform( test_X )\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform( X )\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "sizes2 = [784,30, 10]\n",
    "EPOCHS = 50\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93dc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d359c065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing predict module\n",
    "\n",
    "import pandas as pd\n",
    "path = r\"C:\\Users\\malfaro\\Desktop\\mae_code\\NeuralNetworksMae\\datasets\\diabetes\\diabetes_total_vieja.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33af81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes2 = [8,80, 2]\n",
    "EPOCHS = 500\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d17238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training......\n",
      "Average Error epoch 100: 0.10066244496334997---Average Accuracy: 0.8543478260869565\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 200: 0.09872757848048995---Average Accuracy: 0.8586956521739131\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 300: 0.09622582124207944---Average Accuracy: 0.8695652173913043\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 400: 0.09399239450968676---Average Accuracy: 0.8804347826086955\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 500: 0.09194629067836349---Average Accuracy: 0.8782608695652172\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "net1.SGD(X_train,y_train,X_test, y_test, minibatch_size)\n",
    "#net2.Momentum(X_train,y_train,X_test, y_test, minibatch_size, beta = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51ee12f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive accuracy: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "net1.predict(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ba787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mulanic\n",
    "path = r\"C:\\Users\\malfaro\\Desktop\\mae_code\\NeuralNetworksMae\\datasets\\breastCancer\\breastCancer.csv\"\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b46740",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes2 = [8,30, 2]\n",
    "EPOCHS = 25000\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0cb8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training......\n",
      "Average Error epoch 100: 0.02579886782999313---Average Accuracy: 0.8195652173913043\n",
      "Error booster: 0.07727482044862177\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 200: 0.02451710191035509---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.06482130517257552\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 300: 0.023937066560293235---Average Accuracy: 0.8347826086956521\n",
      "Error booster: 0.06872694109670759\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 400: 0.023400513498336984---Average Accuracy: 0.8391304347826086\n",
      "Error booster: 0.0720953670215557\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 500: 0.022813804836479677---Average Accuracy: 0.8369565217391303\n",
      "Error booster: 0.07535143677094511\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 600: 0.022232217780422642---Average Accuracy: 0.8391304347826086\n",
      "Error booster: 0.07777282036882796\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 700: 0.02179521756977046---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.08265380254370447\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 800: 0.021618737542235297---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.08916311208207686\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 900: 0.02151027375527159---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.0962053550049837\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 1000: 0.02151930359042646---Average Accuracy: 0.8521739130434781\n",
      "Error booster: 0.095133005987827\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 1100: 0.021403051563696214---Average Accuracy: 0.8543478260869565\n",
      "Error booster: 0.09422657816875848\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 1200: 0.021133139223105012---Average Accuracy: 0.8543478260869565\n",
      "Error booster: 0.0943361534262557\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 1300: 0.02095351189160088---Average Accuracy: 0.8586956521739131\n",
      "Error booster: 0.08547507710182194\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 1400: 0.02086520670609007---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.07053228977711562\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 1500: 0.02076386771260636---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06021776052611755\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 1600: 0.02067521575404062---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.05576049660861924\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 1700: 0.0205327466663246---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.053031233212927145\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 1800: 0.02043226976436414---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.0557950789824521\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 1900: 0.020499737245140218---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.05797431582517402\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 2000: 0.02055766801307137---Average Accuracy: 0.8652173913043477\n",
      "Error booster: 0.059522690888932785\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 2100: 0.020696447096085556---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.06169969819103708\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2200: 0.02083190900655499---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06396112869010898\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2300: 0.02081083125058169---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.06603087168551296\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2400: 0.020656499153426156---Average Accuracy: 0.8673913043478259\n",
      "Error booster: 0.06676043953925394\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2500: 0.020496600852737298---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.067044388761994\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2600: 0.020297792535610936---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06698063452900883\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2700: 0.0202901020597721---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06762727693472732\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 2800: 0.02050085326336994---Average Accuracy: 0.8673913043478259\n",
      "Error booster: 0.06764256269371899\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 2900: 0.020740593778159157---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.0688108739747355\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 3000: 0.02067974573362136---Average Accuracy: 0.8652173913043476\n",
      "Error booster: 0.07022572267087959\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 3100: 0.020407171151753143---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.07142739168552589\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 3200: 0.020391108099246772---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.07353096279917332\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 3300: 0.020594293097288618---Average Accuracy: 0.8652173913043479\n",
      "Error booster: 0.07520892365854041\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3400: 0.02092374518244233---Average Accuracy: 0.8673913043478262\n",
      "Error booster: 0.07619877259592192\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3500: 0.02072093459453977---Average Accuracy: 0.8717391304347828\n",
      "Error booster: 0.07662508537203991\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3600: 0.02055151524550718---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.07843515513745712\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3700: 0.020321126097965356---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.07917413231096146\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 3800: 0.0200659160297875---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.0799625618292901\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 3900: 0.01994209268409016---Average Accuracy: 0.876086956521739\n",
      "Error booster: 0.08094360438206236\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4000: 0.020136241007149044---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.0808133613083998\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 4100: 0.020165545871650602---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.07997194007361227\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 4200: 0.020092389014901218---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.07945651782628346\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4300: 0.020051670966380872---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.0787225883678055\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4400: 0.0199972224642237---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.07230232687835011\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4500: 0.019935459287182183---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.06685920388805786\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 4600: 0.01984802100158403---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.05892503867181855\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 4700: 0.01994120107516115---Average Accuracy: 0.8782608695652172\n",
      "Error booster: 0.053677864422277344\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 4800: 0.01982954627296858---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.028274800120148647\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 4900: 0.01991151734902797---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.023489717464064745\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 5000: 0.019982803764157092---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.023522907519294693\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 5100: 0.019932734347373606---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.02545910105366909\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 5200: 0.01991023965729954---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.027802199038699765\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 5300: 0.019962864249907328---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.029793251041794262\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 5400: 0.02000273867780943---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.030831535225402412\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 5500: 0.019985103345638834---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.03124809933578654\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 5600: 0.019885230099218158---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.03104242698275998\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 5700: 0.019779690803051034---Average Accuracy: 0.8782608695652173\n",
      "Error booster: 0.03062633737580065\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 5800: 0.019370474864901593---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.0301842781441171\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 5900: 0.019320178542258683---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.029306368072846572\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6000: 0.019397545739362164---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.027713759915513468\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6100: 0.019470166601499212---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.026214658668418954\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 6200: 0.019499614291805235---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.024797665893437838\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6300: 0.01962645469487034---Average Accuracy: 0.8804347826086955\n",
      "Error booster: 0.02362231799518337\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6400: 0.019671637577540636---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.022644652009340224\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 6500: 0.019648617809947727---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022019944150108856\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 6600: 0.019187777068057972---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.021920922223336973\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 6700: 0.01905662828357044---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.021970607634437304\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 6800: 0.01914662710534739---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.022401973180609536\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 6900: 0.01923259046566696---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.024617580315346076\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7000: 0.019296284734138063---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.026678793931139276\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7100: 0.01944595777982888---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.027602146286118713\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 7200: 0.019429652867454798---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.02580793586690323\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7300: 0.01933625072015965---Average Accuracy: 0.8782608695652175\n",
      "Error booster: 0.02467905576656936\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7400: 0.01930753915043659---Average Accuracy: 0.8782608695652175\n",
      "Error booster: 0.024086471845657893\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7500: 0.019318974015054998---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.023333262553054946\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7600: 0.019372736330541655---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.022957263717903704\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7700: 0.0194188407938856---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022800260562124537\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 7800: 0.01950755091657835---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022474043150091706\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 7900: 0.01950023881333149---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022019748714309832\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8000: 0.019394321985932706---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.021513788564046787\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 8100: 0.019363881868204976---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.020906021395627538\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8200: 0.019166060724666412---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.021509047308252226\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8300: 0.019008015353121906---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.022755314449209085\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 8400: 0.01908646655660728---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.02490398108396933\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8500: 0.019341327524585325---Average Accuracy: 0.8782608695652175\n",
      "Error booster: 0.02735582039555392\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8600: 0.01972739853176163---Average Accuracy: 0.8717391304347827\n",
      "Error booster: 0.039587704351284746\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8700: 0.02009217196054894---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.06488939829028\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8800: 0.02000869861620675---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.05410771499007946\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 8900: 0.01989094882754522---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.039866287838957404\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 9000: 0.019919844646893184---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.044853355619662125\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 9100: 0.019913174459797765---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.04872235752579992\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 9200: 0.01972973087888107---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.04870542717811186\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 9300: 0.01950248155681385---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.04543384867400779\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 9400: 0.019348308635620644---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.04747091294134638\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9500: 0.01926357589687849---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.05051640848974111\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9600: 0.019241638122477346---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.04888038918902649\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9700: 0.019241261005929197---Average Accuracy: 0.8869565217391302\n",
      "Error booster: 0.04551339548744328\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9800: 0.019096414566543433---Average Accuracy: 0.8913043478260869\n",
      "Error booster: 0.041609849242535586\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 9900: 0.018814940158401794---Average Accuracy: 0.8956521739130435\n",
      "Error booster: 0.040032655677083404\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10000: 0.018377041001887164---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.04039203512296041\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10100: 0.018337468389854783---Average Accuracy: 0.8913043478260868\n",
      "Error booster: 0.04390705184952145\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10200: 0.018342818142865144---Average Accuracy: 0.8956521739130432\n",
      "Error booster: 0.04267030611542101\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10300: 0.018265730416396387---Average Accuracy: 0.9021739130434783\n",
      "Error booster: 0.04092610182076308\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10400: 0.01815786047570376---Average Accuracy: 0.8999999999999998\n",
      "Error booster: 0.036048745773667144\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 10500: 0.018134615874200552---Average Accuracy: 0.8956521739130432\n",
      "Error booster: 0.03446549955196997\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 10600: 0.01815381284943581---Average Accuracy: 0.8913043478260869\n",
      "Error booster: 0.05101775597879319\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 10700: 0.01810388794772778---Average Accuracy: 0.893478260869565\n",
      "Error booster: 0.08001328370525371\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 10800: 0.018212121860019755---Average Accuracy: 0.8891304347826086\n",
      "Error booster: 0.07662860731967279\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Average Error epoch 10900: 0.018511658956147276---Average Accuracy: 0.8869565217391302\n",
      "Error booster: 0.06700038538590103\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11000: 0.018730445351794776---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.07210710254311603\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11100: 0.018899345635651533---Average Accuracy: 0.8913043478260869\n",
      "Error booster: 0.07335740265971463\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11200: 0.019290655750189224---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.07229842132863289\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 11300: 0.01940084225917169---Average Accuracy: 0.8804347826086955\n",
      "Error booster: 0.06972989986702477\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 11400: 0.019559732411066004---Average Accuracy: 0.876086956521739\n",
      "Error booster: 0.06847735472782872\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 11500: 0.019904760507553406---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.06825159578034418\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 11600: 0.020133939024626332---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.06794610345374368\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 11700: 0.01982781816945864---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.06920942206882166\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Average Error epoch 11800: 0.020065292223517325---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.07737340121937611\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11900: 0.02043994532856119---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.12689491643871748\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12000: 0.02120728585819006---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.13266890331593925\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12100: 0.021784062941716194---Average Accuracy: 0.8608695652173912\n",
      "Error booster: 0.13271687529106546\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Average Error epoch 12200: 0.02190278630262408---Average Accuracy: 0.8608695652173913\n",
      "Error booster: 0.129143587301578\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 12300: 0.0221850682136318---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.1265304025515053\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12400: 0.022190649595198095---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.12606712899670316\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12500: 0.021435891174347684---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.12256561875387964\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12600: 0.02032899530648616---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.05773634092990463\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 12700: 0.020393159865502716---Average Accuracy: 0.8782608695652172\n",
      "Error booster: 0.06746554482925567\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12800: 0.020372807423867288---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.0963171703151671\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 12900: 0.01980771266166138---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.11409147857602808\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 13000: 0.019655947677557614---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.11242597500764047\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 13100: 0.01998730209690704---Average Accuracy: 0.8826086956521741\n",
      "Error booster: 0.035313790472705935\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 13200: 0.020225559854764194---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.030048425789060872\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13300: 0.019723799788152366---Average Accuracy: 0.8956521739130434\n",
      "Error booster: 0.027862320728700672\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 13400: 0.019567738843492576---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.028155734187898927\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13500: 0.018947337956757074---Average Accuracy: 0.8869565217391305\n",
      "Error booster: 0.027533685860394886\n",
      "Accuracy in test set: 0.8831168831168831\n",
      "Average Error epoch 13600: 0.019082070333948882---Average Accuracy: 0.8934782608695654\n",
      "Error booster: 0.027118557267507913\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13700: 0.019303522359585285---Average Accuracy: 0.8934782608695654\n",
      "Error booster: 0.026138995969116747\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13800: 0.019537383023831824---Average Accuracy: 0.8913043478260871\n",
      "Error booster: 0.025015618679152807\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13900: 0.01945454726462261---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.024065485975803064\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14000: 0.019423199764001392---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.023432219017244994\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14100: 0.019378707723834054---Average Accuracy: 0.8913043478260871\n",
      "Error booster: 0.02301043493133707\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14200: 0.019347754024668245---Average Accuracy: 0.8891304347826088\n",
      "Error booster: 0.022662360422107907\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14300: 0.01954095813775701---Average Accuracy: 0.8869565217391305\n",
      "Error booster: 0.021783103537467034\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14400: 0.019630245900693587---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.020929980693936645\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14500: 0.019493135154187897---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.019981589355439876\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14600: 0.01920015568870764---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.01906099268589332\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14700: 0.019122768562395608---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.018223928651532335\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14800: 0.019120134504141125---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.01747776520637296\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14900: 0.019102884436643718---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.017077461773670484\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 15000: 0.019036467657420942---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.016777829302662046\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 15100: 0.01903748213751089---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.01663262412632948\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 15200: 0.019129463168520166---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.016918853109201024\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 15300: 0.019323328723640898---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.017330148448255006\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 15400: 0.01925198219711452---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.01764295553476034\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 15500: 0.019106107231300126---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.03139539106590908\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 15600: 0.019469880418265487---Average Accuracy: 0.8804347826086955\n",
      "Error booster: 0.043853587000075196\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 15700: 0.01915840064506702---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.07149372726910437\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 15800: 0.019202210674703343---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.030185157152680987\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 15900: 0.019184931314931958---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.03293903307589915\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 16000: 0.01923484719613806---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.032720478302762666\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 16100: 0.018929285720256237---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.03208115779061081\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16200: 0.019280139779692295---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.0408061562662751\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16300: 0.019200026038842313---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.04120187851378992\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16400: 0.019267729940750013---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.04236690887303817\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16500: 0.01974081591642594---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.04634941066335027\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 16600: 0.020300088429258865---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.04952452234835604\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 16700: 0.02079305476359882---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.11022840804830565\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 16800: 0.021104664741964266---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.11210419032196287\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16900: 0.021221137149820386---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.11376069575974083\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 17000: 0.021391093651813707---Average Accuracy: 0.8652173913043477\n",
      "Error booster: 0.11740932281102512\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 17100: 0.021835308756164722---Average Accuracy: 0.8608695652173913\n",
      "Error booster: 0.12023406716061139\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 17200: 0.022197401077959---Average Accuracy: 0.8586956521739131\n",
      "Error booster: 0.11865512029727734\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 17300: 0.022651751743081934---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.1198937995562428\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 17400: 0.023352302974892637---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.15127748797524743\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 17500: 0.023743854446427074---Average Accuracy: 0.8521739130434781\n",
      "Error booster: 0.19358516630932923\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 17600: 0.0240695434511238---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.1928850021688077\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 17700: 0.023958150691763432---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.19206340434481992\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 17800: 0.023959386937713264---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.19078015644794544\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 17900: 0.023844883361948278---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.18895474134403142\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 18000: 0.023939155477053574---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.18627261613125048\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 18100: 0.02398933572454144---Average Accuracy: 0.85\n",
      "Error booster: 0.18441537491937887\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 18200: 0.024303882975002782---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.1824533116462897\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 18300: 0.024812925514769314---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.18184172033177531\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 18400: 0.02486937087853349---Average Accuracy: 0.85\n",
      "Error booster: 0.1840597874765424\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 18500: 0.02493879978598971---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.18565147178443472\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 18600: 0.025230307286361737---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.18725378641321064\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 18700: 0.025416739307109856---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.18576998548911366\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 18800: 0.0258439810553242---Average Accuracy: 0.8369565217391305\n",
      "Error booster: 0.1787089178289618\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 18900: 0.0260563428149313---Average Accuracy: 0.8369565217391306\n",
      "Error booster: 0.17446787332746477\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 19000: 0.02644574337595465---Average Accuracy: 0.8391304347826086\n",
      "Error booster: 0.16765072671952103\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 19100: 0.02645153071566213---Average Accuracy: 0.8326086956521739\n",
      "Error booster: 0.15525778498704473\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 19200: 0.02621557894201356---Average Accuracy: 0.8282608695652173\n",
      "Error booster: 0.150473716738812\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 19300: 0.025970740635987498---Average Accuracy: 0.8369565217391303\n",
      "Error booster: 0.15046559972703916\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 19400: 0.025904878969929237---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.1500328400729216\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19500: 0.0256100389464566---Average Accuracy: 0.834782608695652\n",
      "Error booster: 0.14759712987196966\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19600: 0.02559808486135388---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.14620397669043209\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19700: 0.025179686698539303---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.1427254870872886\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19800: 0.025544885408236916---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.13972454249305646\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 19900: 0.02572489700963137---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.13843743259581626\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20000: 0.02538732859130488---Average Accuracy: 0.841304347826087\n",
      "Error booster: 0.13997457956872444\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20100: 0.02518094219663699---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.14264425814835024\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20200: 0.025289707724057208---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.1255718880885193\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20300: 0.02526484347371449---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.12432650393606784\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20400: 0.024938949301373733---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.07421422139829861\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 20500: 0.024873414303089668---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.0757431112176641\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 20600: 0.02496429106872455---Average Accuracy: 0.8543478260869565\n",
      "Error booster: 0.07636674246166467\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 20700: 0.02498869335451368---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.07624887736702098\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 20800: 0.025134873012516715---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.07399381251643436\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 20900: 0.02525512033526579---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.07167884097803386\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21000: 0.02530383198681924---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06872970670080963\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21100: 0.02554025219276368---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.06565994171032671\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 21200: 0.025698487854023688---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06111874559920477\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21300: 0.025557690600679608---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.05378260889877422\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21400: 0.02553564828961736---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.05010065332415137\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 21500: 0.025273247900592304---Average Accuracy: 0.8456521739130433\n",
      "Error booster: 0.04914109918579819\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21600: 0.02484800758838105---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.05461084044818439\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 21700: 0.024746676601495023---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.052329885027810816\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 21800: 0.024719370236113185---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.05083689247511669\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 21900: 0.024836116908666547---Average Accuracy: 0.85\n",
      "Error booster: 0.06286066224656274\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 22000: 0.02489569404266987---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06883818513345166\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 22100: 0.024649032159151794---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06383294412998616\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 22200: 0.024564809892146735---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.05884405936933508\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 22300: 0.024327993807003446---Average Accuracy: 0.85\n",
      "Error booster: 0.05647609085173213\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 22400: 0.024089480235329433---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.05563692882638778\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 22500: 0.024020651275499773---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.052738170464311326\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 22600: 0.02413817603545054---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05270051293635843\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 22700: 0.02396992076736378---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05279109059581215\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 22800: 0.023659004187245477---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05314431686889722\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 22900: 0.023475491349601068---Average Accuracy: 0.8608695652173913\n",
      "Error booster: 0.05245365151015766\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23000: 0.023318023240777794---Average Accuracy: 0.8608695652173912\n",
      "Error booster: 0.053192413730368183\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 23100: 0.02290115496782703---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05322817766456446\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23200: 0.022798561673759033---Average Accuracy: 0.8608695652173912\n",
      "Error booster: 0.05465586132766087\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23300: 0.02287935392235369---Average Accuracy: 0.8630434782608696\n",
      "Error booster: 0.058103210047723786\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 23400: 0.02276280379271736---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.06131907214952561\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 23500: 0.023005122198426712---Average Accuracy: 0.8586956521739131\n",
      "Error booster: 0.06623063852481172\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23600: 0.023270685158877893---Average Accuracy: 0.8543478260869566\n",
      "Error booster: 0.0775920598892613\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23700: 0.023677121955728034---Average Accuracy: 0.8543478260869566\n",
      "Error booster: 0.08266277753539632\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 23800: 0.024283013737684024---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.08556943245575852\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 23900: 0.024467210820930826---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.08660622583332488\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 24000: 0.024540954384816852---Average Accuracy: 0.8521739130434781\n",
      "Error booster: 0.08555495209081004\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 24100: 0.024782956550099714---Average Accuracy: 0.85\n",
      "Error booster: 0.08471504001472648\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 24200: 0.024804184791774885---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.09042155006080131\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 24300: 0.024928209875659378---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.09571470940194576\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24400: 0.024604412515928095---Average Accuracy: 0.85\n",
      "Error booster: 0.09519813690503594\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 24500: 0.024658015332466577---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.09574219591414787\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 24600: 0.02466099525711068---Average Accuracy: 0.85\n",
      "Error booster: 0.09838811109296389\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24700: 0.024727227248908745---Average Accuracy: 0.85\n",
      "Error booster: 0.10080533672688878\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24800: 0.024645961580766283---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.1014876315990932\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24900: 0.02471952390340635---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.10231496615593835\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 25000: 0.02471625805665003---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.10202135549430984\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Training complete!\n",
      "Validation...\n",
      "------------------------------------------------------------------\n",
      "Predictive accuracy: 0.6558441558441559\n"
     ]
    }
   ],
   "source": [
    "net1.SGD(X_train,y_train,X_test, y_test, minibatch_size)\n",
    "print(\"Validation...\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "net2.predict(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ae9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_data = np.load(\"saved_training_data.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a877eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    \"\"\"Splits the generated dataset into X and y for training purposes\"\"\"\n",
    "    X = np.array([data[i][0] for i in range(len(data))])\n",
    "    y = np.array([data[i][1] for i in range(len(data))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "13071c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data(cart_data)\n",
    "\n",
    "y_t = np.argmax(y)\n",
    "y_t = []\n",
    "for i in y:\n",
    "    y_t.append(np.argmax(i))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_t), test_size=0.3, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# (unique, counts) = np.unique(y_t, return_counts=True)\n",
    "# frequencies = np.asarray((unique, counts/len(y_t))).T\n",
    "# frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f73653df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes2 = [4, 128, 256, 128, 2]\n",
    "EPOCHS = 500\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(),Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 3)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(),Sigmoid(),Sigmoid(),Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5e116813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training......\n",
      "Average Error epoch 100: 8.104178543021847---Average Accuracy: 0.49720000000000003\n",
      "Accuracy in test set: 0.5034\n",
      "Average Error epoch 200: 8.104178543021847---Average Accuracy: 0.49720000000000003\n",
      "Accuracy in test set: 0.5034\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-69a245b42d9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnet2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-18f9e368d1b0>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, X, y, x_test, y_test, minibatch_size)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m                 \u001b[1;31m#Calcular el error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivated_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-18f9e368d1b0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivated_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivated_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nr = 5000\n",
    "net2.SGD(X_train[:nr],y_train[:nr],X_test[:nr], y_test[:nr], minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "235014d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive accuracy: 0.46411067857843\n"
     ]
    }
   ],
   "source": [
    "net1.predict(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d07d583c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57528022, 0.42471978],\n",
       "       [0.57528022, 0.42471978],\n",
       "       [0.36188863, 0.63811137],\n",
       "       [0.57528022, 0.42471978],\n",
       "       [0.36188863, 0.63811137]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1.prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "77f72717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01361164, -0.00534999, -0.0108652 , -0.03312088], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "# import numpy as np\n",
    "# import tflearn\n",
    "# from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "# from tflearn.layers.estimator import regression\n",
    "# from statistics import median, mean\n",
    "# from collections import Counter\n",
    "\n",
    "LR = 1e-3\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a287fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 10.4254\n",
      "choice 1:0.04820918142229555  choice 0:0.9517908185777044\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "choices = []\n",
    "goal_steps = 200\n",
    "score_requirement = 50\n",
    "for each_game in range(5000):\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    prev_obs = []\n",
    "    env.reset()\n",
    "    for _ in range(goal_steps):\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            #action = np.argmax(net2.forward(prev_obs.reshape(-1,len(prev_obs),1))[0])\n",
    "            action = np.argmax(net2.forward(prev_obs))\n",
    "\n",
    "        choices.append(action)\n",
    "                \n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        game_memory.append([new_observation, action])\n",
    "        score+=reward\n",
    "        if done: break\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "print('Average Score:',sum(scores)/len(scores))\n",
    "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "print(score_requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc04c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
