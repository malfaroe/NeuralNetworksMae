{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "238276a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "#display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\"))\n",
    "#display(HTML(\"<style>.prompt { display:none !important; }</style>\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2ddfc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "\n",
    "    def __init__(self, sizes, activations, Loss, epochs, metric, learning_rate):\n",
    "        self.weights =[np.random.randn(sizes[i],sizes[i-1]) for i in range(1, len(sizes))]\n",
    "        self.biases =  [np.zeros((1, sizes[i])) for i in range(1, len(sizes))]\n",
    "        self.activations = activations\n",
    "        self.Loss = Loss\n",
    "        self.epochs = epochs\n",
    "        self.metric = metric\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        self.activated_layers = [x]\n",
    "        for w,b, act in zip(self.weights, self.biases, self.activations):\n",
    "            activation = act.activate(np.dot(x, w.T) + b)\n",
    "            self.activated_layers.append(activation)\n",
    "            x = activation\n",
    "            \n",
    "            \n",
    "    def backpropagate(self, y):\n",
    "        #Input: activated_layers\n",
    "        #output: Container Gradient dE/dw \n",
    "        #Initialize\n",
    "        sigmas_box = []\n",
    "        sigma_prime_box = []\n",
    "    \n",
    "       #Backprop the error ()\n",
    "        #1. Compute output layer sigma\n",
    "        loss_grad = self.Loss.loss_gradient(self.activated_layers[-1], y)\n",
    "        output_sigma = self.activations[-1].output_layer_sigma(loss_grad, self.activated_layers[-1])\n",
    "        sigmas_box = [output_sigma]\n",
    "        #Sigmas of the rest of layers...\n",
    "        for w,a,o_layer in zip(self.weights[::-1], self.activations[:-1][::-1],self.activated_layers[:-1][::-1]) :\n",
    "            sigmas_box.append(np.dot(sigmas_box[-1], w) * a.sigma_prime(o_layer))\n",
    "       \n",
    "        #Reverse sigma_box    \n",
    "        sigmas_box.reverse()\n",
    "        #Biases update\n",
    "        self.grad_biases = sigmas_box\n",
    "        #Gradient (dE/dw):\n",
    "        self.gradients = []\n",
    "        for a, s in zip(self.activated_layers[:-1], sigmas_box):\n",
    "            self.gradients.append(np.dot(s.T, a))\n",
    "        #Nota: al hacerse la multiplicacion de todos los inputs a la vez\n",
    "        #Igual se mantiene el shape de cada weight pero mientras más\n",
    "        #Inputs más grandes salen los valores de cada componente de la matriz\n",
    "        #Por eso después se divide cada weight por el total de inputs (mean)\n",
    "        # print(\"Gradients shapes:\")\n",
    "        # for g in gradients:\n",
    "        #     print(g.shape)\n",
    "       \n",
    "\n",
    "    def weight_update(self):\n",
    "        for w,gw, b, gb in zip(self.weights, self.gradients, self.biases, self.grad_biases):\n",
    "            w -= (self.learning_rate / len(X))* gw\n",
    "            b -= (self.learning_rate / len(gb))* np.sum(gb, axis= 0)\n",
    "\n",
    "        return self.weights, self.biases\n",
    "        \n",
    "    \n",
    "    def predict(self, X,y):\n",
    "            self.forward(X)\n",
    "            self.prediction = self.activated_layers[-1]\n",
    "            #Compute the accuracy\n",
    "            acc = self.metric.get_accuracy(self.prediction, y)\n",
    "            print(\"Predictive accuracy:\", acc)\n",
    "\n",
    "\n",
    "            \n",
    "    def SGD(self, X,y,x_test, y_test, minibatch_size):\n",
    "        \"\"\"Vectorized version of Minibatch Stochastic Gradient Descent\"\"\"\n",
    "        print(\"Minibatch SGD Training......\")\n",
    "        Losses = [] #saves the loss of each epoch\n",
    "        for e in range(1, self.epochs + 1):\n",
    "            #tomar dataset y generar minibatches box\n",
    "            minibatches = self.minibatch_generator(X,y, minibatch_size)\n",
    "            Accuracies = []\n",
    "            for mb in minibatches:\n",
    "                input = mb[0]\n",
    "                y_true = np.array(mb[1]).astype(int)\n",
    "                #Obtener los gradientes del minibatch usando backprop\n",
    "                self.forward(input)\n",
    "                self.backpropagate(y_true)\n",
    "                delta_nw = self.gradients #dC/dw\n",
    "                delta_nb = self.grad_biases #dC/db\n",
    "                #Updating the parameters \n",
    "                self.weights = [w - (self.learning_rate/ len(mb)) * dw for w,dw in zip(self.weights, delta_nw)]\n",
    "                self.biases = [b - (self.learning_rate/ len(mb)) * np.sum(db, axis = 0) for b, db in zip(self.biases, delta_nb)]\n",
    "            \n",
    "            #Reporte de error y accuracy por epoch...\n",
    "            #Para evaluar como va se calcula el error del epoch usando todo el dataset como corresponde\n",
    "            self.forward(X)\n",
    "            y_output = self.activated_layers[-1]\n",
    "            error = self.Loss.forward_loss(y_output, y)\n",
    "            acc = self.metric.get_accuracy(y_output, y)\n",
    "            Losses.append(error)\n",
    "\n",
    "            if (e % 100 == 0 ) or (e == self.epochs):\n",
    "                print(\"Error epoch {0}: {1}--- Accuracy: {2}\".format(e, error, acc))\n",
    "                print(\"Accuracy in test set:\", self.evaluate_test(x_test, y_test))\n",
    "        #Plotting\n",
    "        x_label = np.arange(1, self.epochs +1)\n",
    "        plt.plot(x_label, Losses)\n",
    "        plt.show()\n",
    "                   \n",
    "        print(\"Training complete!\")         \n",
    "\n",
    "\n",
    "    def MomentumGD(self, X,y,x_test, y_test, beta = 0.9):\n",
    "        \"\"\"Vectorized version\"\"\"\n",
    "        print(\"Momentum Training......\")\n",
    "        #Parameters initialization\n",
    "        #Velocities initialization\n",
    "        Vdw = [np.zeros(w.shape) for w in self.weights]\n",
    "        Vdb = [np.zeros(b.shape) for b in self.biases]\n",
    "        Losses = []\n",
    "        Accuracies = []\n",
    "        for e in range(1, self.epochs + 1):\n",
    "                self.forward(X)\n",
    "                #Calcular el error\n",
    "                error = self.Loss.forward_loss(self.activated_layers[-1], y)\n",
    "                acc = self.metric.get_accuracy(self.activated_layers[-1], y)\n",
    "                #Guardar el error y accuracy\n",
    "                Losses.append(error)\n",
    "                Accuracies.append(acc)\n",
    "                #Obtener los gradientes respectivos usando backprop\n",
    "                self.backpropagate(y)\n",
    "                delta_nw = self.gradients #dC/dw\n",
    "                delta_nb = self.grad_biases #dC/db\n",
    "                \n",
    "                #Compute the exp moving averages (velocities)\n",
    "                Vdw = [beta * vw + self.learning_rate * dnw for vw, dnw in zip(Vdw, delta_nw)]\n",
    "                Vdb = [beta * vb +  self.learning_rate * dnb.mean() for vb, dnb in zip(Vdb, delta_nb)]\n",
    "                \n",
    "                #Update weights and biases using the Velocities\n",
    "                \n",
    "                self.weights = [w - vdw for w,vdw in zip(self.weights, Vdw)]\n",
    "                self.biases = [b - vdb for b, vdb in zip(self.biases, Vdb)]\n",
    "                ''' print(\"Weights shapes:\")\n",
    "                for w in self.weights:\n",
    "                    print(w.shape)\n",
    "                print(\"Biases shapes:\")\n",
    "                for b in self.biases:\n",
    "                    print(b.shape) '''\n",
    "\n",
    "            #Reporte de error y accuracy por epoch...\n",
    "\n",
    "                if (e % 100 == 0 ) or (e == self.epochs):\n",
    "                    print(\"Error epoch {0}: {1}--- Accuracy: {2}\".format(e, error, acc))\n",
    "                    print(\"Accuracy in test set:\", self.evaluate_test(x_test, y_test))\n",
    "        \n",
    "        ##Plotting cost\n",
    "        print(\"Initial loss:\", Losses[1])\n",
    "        print(\"Final loss after {0} iterations: {1}\".format(self.epochs, Losses[-1]))\n",
    "        #Plotting\n",
    "        x_label = np.arange(1, self.epochs +1)\n",
    "        plt.plot(x_label, Losses)\n",
    "        plt.show()\n",
    "                   \n",
    "        print(\"Training complete!\") \n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "    def minibatch_generator(self, X,y, batch_size):\n",
    "        \"\"\"\"Generates minibatches with no replacement\"\"\"\n",
    "        dataset = list(zip(X,np.array(y)))\n",
    "        np.random.shuffle(dataset)\n",
    "        minibatches = [(X[i:i+batch_size], y[i:i+batch_size]) for\n",
    "                        i in range(0, len(y), batch_size)]\n",
    "                        \n",
    "        #si minibatch final es mas chico que el batch size se le mete desde\n",
    "        #atras inputs hasta completar el tamaño batch size\n",
    "        if len(minibatches[-1][0]) < batch_size:\n",
    "            minibatches[-1] = (X[-batch_size:], y[-batch_size:])\n",
    "            \n",
    "        return minibatches\n",
    "    \n",
    "    def evaluate_test(self, x_test, y_test):\n",
    "        \"\"\"Evaluates the model on the test set\n",
    "        input: x_test, y_test\n",
    "        output: accuracy\"\"\"\n",
    "        #Forward pass---obtain prediction y_pred\n",
    "        self.forward(x_test)\n",
    "        #Evaluate prediction with accuracy\n",
    "        acc_test = self.metric.get_accuracy(self.activated_layers[-1], y_test)\n",
    "        #Return accuracy\n",
    "        return acc_test\n",
    "\n",
    "        \n",
    " \n",
    "class Relu():\n",
    "    def activate(self, x):\n",
    "        self.output = np.maximum(0,x)\n",
    "        return self.output\n",
    "    \n",
    "    def sigma_prime(self, x):\n",
    "        return 1. * (x > 0)\n",
    "\n",
    "\n",
    "class Sigmoid():\n",
    "    def activate(self, x):\n",
    "        #np.exp - (x - np.max(x, axis = 1, keepdims= True))\n",
    "        x = np.clip(x, 1e-7, 1 - 1e-7)\n",
    "        self.output = 1 / (1+ np.exp (- (x - np.max(x, axis = 1, keepdims= True))))\n",
    "        #self.output = 1 / (1+ np.exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def output_layer_sigma(self, loss_gradients, x):\n",
    "        \"\"\"en realidad calcula todo el sigma de una vez como dC/da * sigma_prime\n",
    "        dC/da = loss_gradient\"\"\"\n",
    "        \n",
    "        self.output_sigma = loss_gradients * self.sigma_prime(x)\n",
    "        return self.output_sigma\n",
    "    \n",
    "    def sigma_prime(self, x):\n",
    "        return x * (1-x)\n",
    "\n",
    "class Softmax():\n",
    "    def activate(self, x):\n",
    "        #Get unnormalized probs\n",
    "        exp_values = np.exp(x - np.max(x, axis = 1, keepdims= True))\n",
    "        #Get normalized probs\n",
    "        self.output = exp_values / np.sum(exp_values, axis= 1, keepdims= True)\n",
    "        return self.output\n",
    "    \n",
    "    def output_layer_sigma(self, loss_gradients, out_activations):\n",
    "        \"\"\"Dado que es complejo multplicar el jacobiano de cada input por\n",
    "        #su loss_gradient por que el jac es una matrix, se hace aca todo directo y se saca \n",
    "        #el output layer sigma = dE/dsigma.dsigma/dz\"\"\"\n",
    "        #Se crea un contenedor donde irá el output_sigma de cada input\n",
    "        #del tamaño del loss_gradient (dinputs)\n",
    "        self.output_sigma = np.empty_like(loss_gradients)\n",
    "\n",
    "        #Tomo uno a uno los Loss_gradientes de cada input y cada\n",
    "        #softmax activation de la output layer para hacer uno a uno los\n",
    "        #output_sigmas...\n",
    "        for index, (single_act, single_loss_grad) in enumerate(zip(out_activations, loss_gradients)):\n",
    "            single_act = single_act.reshape(-1,1)\n",
    "            #Calculate jacobian matrix (sigma_prime of softmax)\n",
    "            jacobian_matrix = np.diagflat(single_act) - np.dot(single_act, single_act.T)\n",
    "            self.output_sigma[index] = np.dot(jacobian_matrix, single_loss_grad)\n",
    "        return self.output_sigma\n",
    "\n",
    "         \n",
    "\n",
    "    \n",
    "##Loss Units\n",
    "class MSE():\n",
    "    \n",
    "    #Forward\n",
    "    def forward_loss(self, y_pred, y_true):\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        labels = len(y_pred[0])                  \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        #return  np.sum((y_pred- y_true)**2, axis=1) / len(y_pred)\n",
    "        return ((y_pred- y_true)**2).mean()\n",
    "        \n",
    "    #Derivative\n",
    "    def loss_gradient(self, y_pred, y_true): #dE/dact\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        labels = len(y_pred[0])                  \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        self.dinputs = (2/len(y_pred)) * (y_pred - y_true)\n",
    "        return self.dinputs\n",
    "    \n",
    "    \n",
    "class CategoricalCrossEntropyLoss():\n",
    "    def forward_loss(self, y_pred, y_true):\n",
    "         #entrega el vector de negative losses de cada sample\n",
    "         y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7) #recorta para evitar logs mulas\n",
    "         if len(y_true.shape) == 1: #si el y_true viene en un solo vector de escalares\n",
    "             #extraigo el valor que tiene el indice indicado en el y_true\n",
    "             #correspondiente\n",
    "             correct_confidences = y_pred[range(len(y_pred)), y_true]\n",
    "        \n",
    "         if len(y_true.shape) == 2: #matrix\n",
    "             #lo mismo pero multiplique y sume para obtener el valor\n",
    "             #que tiene el indice indicado por el y_true (el resto se hace zero\n",
    "             #al multiplicar)\n",
    "             correct_confidences = np.sum( y_pred * y_true, axis = 1)\n",
    "        \n",
    "         negative_loss_likehoods = -np.log(correct_confidences)\n",
    "\n",
    "         return np.mean(negative_loss_likehoods)\n",
    "    \n",
    "    def loss_gradient(self, dvalues, y_true): #dE/dact\n",
    "        # Number of samples\n",
    "        dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "        return self.dinputs\n",
    "\n",
    "\n",
    "\n",
    "class Accuracy():\n",
    "#gets the accuracy of the training stage\n",
    "    def get_accuracy(self, y_pred, y_true):\n",
    "        #saca el indice donde esta el valor mas grande\n",
    "        predictions = np.argmax(y_pred, axis= 1)\n",
    "\n",
    "        #y_true en formato escalares\n",
    "        if len(y_true.shape) == 1:\n",
    "            accuracy = np.mean(predictions == y_true)\n",
    "        #matrix\n",
    "        elif len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis= 1)\n",
    "            accuracy = np.mean(predictions == y_true) #promedia coincidencias de valor de indice\n",
    "\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50b3464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data \n",
    "y_iris= iris.target\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_iris)\n",
    "\n",
    "X_scaled = scaler.transform(X_iris)\n",
    "\n",
    "sizes = [4, 10, 3]\n",
    "EPOCHS = 50\n",
    "net3 = Dense(sizes, activations = [Relu(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "                 epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9c585571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"mnist_train.csv\", delimiter= \",\")\n",
    "X = train.iloc[:, 1:]\n",
    "y = train.iloc[:, 0]\n",
    "\n",
    "#Loading test set\n",
    "test = pd.read_csv(\"mnist_test.csv\", delimiter= \",\")\n",
    "x_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# X = scaler.transform(X)\n",
    "# test_X = scaler.transform( test_X )\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform( X )\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "sizes2 = [784,30, 10]\n",
    "EPOCHS = 50\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d359c065",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing predict module\n",
    "\n",
    "import pandas as pd\n",
    "path = r\"C:\\Users\\malfaro\\Desktop\\mae_code\\NeuralNetworksMae\\datasets\\diabetes\\diabetes_total_vieja.csv\"\n",
    "path_mac = r\"/Users/mauricioalfaro/Documents/mae_code/NeuralNetworksMae/datasets/diabetes/diabetes_total_vieja.csv\"\n",
    "\n",
    "#df = pd.read_csv(path)\n",
    "df = pd.read_csv(path_mac)\n",
    "\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "33af81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes2 = [8,80, 2]\n",
    "EPOCHS = 5000\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "\n",
    "\n",
    "y_pred =np.array([[0.3, 0.7], [0.6, 0.4]])\n",
    "y_true =np.array([[0, 1], [0, 1]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76d17238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum Training......\n",
      "Error epoch 100: 0.45035361219797027--- Accuracy: 0.808695652173913\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 200: 0.4375357124545535--- Accuracy: 0.8152173913043478\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 300: 0.4241021296675977--- Accuracy: 0.8260869565217391\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Error epoch 400: 0.40925462706205346--- Accuracy: 0.8369565217391305\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 500: 0.3968350429256959--- Accuracy: 0.8391304347826087\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 600: 0.3866351014230236--- Accuracy: 0.8369565217391305\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 700: 0.3794346736984813--- Accuracy: 0.8391304347826087\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 800: 0.3726806951255332--- Accuracy: 0.841304347826087\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 900: 0.366559266100866--- Accuracy: 0.8434782608695652\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 1000: 0.3608655691776043--- Accuracy: 0.8478260869565217\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 1100: 0.35592039609639103--- Accuracy: 0.8456521739130435\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 1200: 0.35153318147407603--- Accuracy: 0.8456521739130435\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Error epoch 1300: 0.34744751503630616--- Accuracy: 0.85\n",
      "Accuracy in test set: 0.7987012987012987\n",
      "Error epoch 1400: 0.34294277364433856--- Accuracy: 0.8565217391304348\n",
      "Accuracy in test set: 0.7987012987012987\n",
      "Error epoch 1500: 0.3381637024144279--- Accuracy: 0.8586956521739131\n",
      "Accuracy in test set: 0.7987012987012987\n",
      "Error epoch 1600: 0.3339206737904439--- Accuracy: 0.8695652173913043\n",
      "Accuracy in test set: 0.7987012987012987\n",
      "Error epoch 1700: 0.330813604020016--- Accuracy: 0.8695652173913043\n",
      "Accuracy in test set: 0.7987012987012987\n",
      "Error epoch 1800: 0.3285720476030177--- Accuracy: 0.8739130434782608\n",
      "Accuracy in test set: 0.7987012987012987\n",
      "Error epoch 1900: 0.327455198098479--- Accuracy: 0.8760869565217392\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Error epoch 2000: 0.3269313341426338--- Accuracy: 0.8760869565217392\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 2100: 0.3271394314617681--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 2200: 0.3272238411002956--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 2300: 0.3271283274173009--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Error epoch 2400: 0.3275616864690712--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 2500: 0.32828740914282784--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Error epoch 2600: 0.3282870905217075--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Error epoch 2700: 0.3272235830308284--- Accuracy: 0.8760869565217392\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 2800: 0.32557853321928076--- Accuracy: 0.8760869565217392\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 2900: 0.32456990807734265--- Accuracy: 0.8739130434782608\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 3000: 0.32372944128292935--- Accuracy: 0.8739130434782608\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Error epoch 3100: 0.32218722937379396--- Accuracy: 0.8804347826086957\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 3200: 0.3205049698432559--- Accuracy: 0.8826086956521739\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Error epoch 3300: 0.31882907065002036--- Accuracy: 0.8869565217391304\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 3400: 0.3171858660559766--- Accuracy: 0.8869565217391304\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Error epoch 3500: 0.31644774788203983--- Accuracy: 0.8913043478260869\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Error epoch 3600: 0.3161278701128002--- Accuracy: 0.8869565217391304\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Error epoch 3700: 0.3157956882037251--- Accuracy: 0.8826086956521739\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 3800: 0.3155337566057164--- Accuracy: 0.8847826086956522\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 3900: 0.3152747292286549--- Accuracy: 0.8826086956521739\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 4000: 0.3152159400151005--- Accuracy: 0.8826086956521739\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 4100: 0.31526604929646024--- Accuracy: 0.8804347826086957\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 4200: 0.3155861366754217--- Accuracy: 0.8760869565217392\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 4300: 0.3167187375620389--- Accuracy: 0.8760869565217392\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 4400: 0.317697753487493--- Accuracy: 0.8739130434782608\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 4500: 0.31816373041358126--- Accuracy: 0.8739130434782608\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 4600: 0.3185053642962442--- Accuracy: 0.8739130434782608\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Error epoch 4700: 0.31833692296857263--- Accuracy: 0.8717391304347826\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 4800: 0.3179704837133183--- Accuracy: 0.8652173913043478\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 4900: 0.3175654450192688--- Accuracy: 0.8630434782608696\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Error epoch 5000: 0.3167300327242514--- Accuracy: 0.8608695652173913\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Initial loss: 0.8369653550849179\n",
      "Final loss after 5000 iterations: 0.3167300327242514\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "net2.MomentumGD(X_train,y_train,X_test, y_test, minibatch_size, beta = 0.9)\n",
    "#net2.SGD(X_train,y_train,X_test, y_test, minibatch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "51ee12f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive accuracy: 0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "net2.predict(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ba787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mulanic\n",
    "path = r\"C:\\Users\\malfaro\\Desktop\\mae_code\\NeuralNetworksMae\\datasets\\breastCancer\\breastCancer.csv\"\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b46740",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes2 = [8,30, 2]\n",
    "EPOCHS = 25000\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.05)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0cb8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Training......\n",
      "Average Error epoch 100: 0.02579886782999313---Average Accuracy: 0.8195652173913043\n",
      "Error booster: 0.07727482044862177\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 200: 0.02451710191035509---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.06482130517257552\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 300: 0.023937066560293235---Average Accuracy: 0.8347826086956521\n",
      "Error booster: 0.06872694109670759\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 400: 0.023400513498336984---Average Accuracy: 0.8391304347826086\n",
      "Error booster: 0.0720953670215557\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 500: 0.022813804836479677---Average Accuracy: 0.8369565217391303\n",
      "Error booster: 0.07535143677094511\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 600: 0.022232217780422642---Average Accuracy: 0.8391304347826086\n",
      "Error booster: 0.07777282036882796\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 700: 0.02179521756977046---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.08265380254370447\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 800: 0.021618737542235297---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.08916311208207686\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 900: 0.02151027375527159---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.0962053550049837\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 1000: 0.02151930359042646---Average Accuracy: 0.8521739130434781\n",
      "Error booster: 0.095133005987827\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 1100: 0.021403051563696214---Average Accuracy: 0.8543478260869565\n",
      "Error booster: 0.09422657816875848\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 1200: 0.021133139223105012---Average Accuracy: 0.8543478260869565\n",
      "Error booster: 0.0943361534262557\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 1300: 0.02095351189160088---Average Accuracy: 0.8586956521739131\n",
      "Error booster: 0.08547507710182194\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 1400: 0.02086520670609007---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.07053228977711562\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 1500: 0.02076386771260636---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06021776052611755\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 1600: 0.02067521575404062---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.05576049660861924\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 1700: 0.0205327466663246---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.053031233212927145\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 1800: 0.02043226976436414---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.0557950789824521\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 1900: 0.020499737245140218---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.05797431582517402\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 2000: 0.02055766801307137---Average Accuracy: 0.8652173913043477\n",
      "Error booster: 0.059522690888932785\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 2100: 0.020696447096085556---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.06169969819103708\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2200: 0.02083190900655499---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06396112869010898\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2300: 0.02081083125058169---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.06603087168551296\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2400: 0.020656499153426156---Average Accuracy: 0.8673913043478259\n",
      "Error booster: 0.06676043953925394\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2500: 0.020496600852737298---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.067044388761994\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2600: 0.020297792535610936---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06698063452900883\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 2700: 0.0202901020597721---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.06762727693472732\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 2800: 0.02050085326336994---Average Accuracy: 0.8673913043478259\n",
      "Error booster: 0.06764256269371899\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 2900: 0.020740593778159157---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.0688108739747355\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 3000: 0.02067974573362136---Average Accuracy: 0.8652173913043476\n",
      "Error booster: 0.07022572267087959\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 3100: 0.020407171151753143---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.07142739168552589\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 3200: 0.020391108099246772---Average Accuracy: 0.8673913043478261\n",
      "Error booster: 0.07353096279917332\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 3300: 0.020594293097288618---Average Accuracy: 0.8652173913043479\n",
      "Error booster: 0.07520892365854041\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3400: 0.02092374518244233---Average Accuracy: 0.8673913043478262\n",
      "Error booster: 0.07619877259592192\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3500: 0.02072093459453977---Average Accuracy: 0.8717391304347828\n",
      "Error booster: 0.07662508537203991\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3600: 0.02055151524550718---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.07843515513745712\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 3700: 0.020321126097965356---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.07917413231096146\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 3800: 0.0200659160297875---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.0799625618292901\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 3900: 0.01994209268409016---Average Accuracy: 0.876086956521739\n",
      "Error booster: 0.08094360438206236\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4000: 0.020136241007149044---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.0808133613083998\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 4100: 0.020165545871650602---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.07997194007361227\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 4200: 0.020092389014901218---Average Accuracy: 0.8695652173913042\n",
      "Error booster: 0.07945651782628346\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4300: 0.020051670966380872---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.0787225883678055\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4400: 0.0199972224642237---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.07230232687835011\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 4500: 0.019935459287182183---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.06685920388805786\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 4600: 0.01984802100158403---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.05892503867181855\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 4700: 0.01994120107516115---Average Accuracy: 0.8782608695652172\n",
      "Error booster: 0.053677864422277344\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 4800: 0.01982954627296858---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.028274800120148647\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 4900: 0.01991151734902797---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.023489717464064745\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 5000: 0.019982803764157092---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.023522907519294693\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 5100: 0.019932734347373606---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.02545910105366909\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 5200: 0.01991023965729954---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.027802199038699765\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 5300: 0.019962864249907328---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.029793251041794262\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 5400: 0.02000273867780943---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.030831535225402412\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 5500: 0.019985103345638834---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.03124809933578654\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 5600: 0.019885230099218158---Average Accuracy: 0.8739130434782609\n",
      "Error booster: 0.03104242698275998\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 5700: 0.019779690803051034---Average Accuracy: 0.8782608695652173\n",
      "Error booster: 0.03062633737580065\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 5800: 0.019370474864901593---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.0301842781441171\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 5900: 0.019320178542258683---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.029306368072846572\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6000: 0.019397545739362164---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.027713759915513468\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6100: 0.019470166601499212---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.026214658668418954\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 6200: 0.019499614291805235---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.024797665893437838\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6300: 0.01962645469487034---Average Accuracy: 0.8804347826086955\n",
      "Error booster: 0.02362231799518337\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 6400: 0.019671637577540636---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.022644652009340224\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 6500: 0.019648617809947727---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022019944150108856\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 6600: 0.019187777068057972---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.021920922223336973\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 6700: 0.01905662828357044---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.021970607634437304\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 6800: 0.01914662710534739---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.022401973180609536\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 6900: 0.01923259046566696---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.024617580315346076\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7000: 0.019296284734138063---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.026678793931139276\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7100: 0.01944595777982888---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.027602146286118713\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 7200: 0.019429652867454798---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.02580793586690323\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7300: 0.01933625072015965---Average Accuracy: 0.8782608695652175\n",
      "Error booster: 0.02467905576656936\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7400: 0.01930753915043659---Average Accuracy: 0.8782608695652175\n",
      "Error booster: 0.024086471845657893\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7500: 0.019318974015054998---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.023333262553054946\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7600: 0.019372736330541655---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.022957263717903704\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 7700: 0.0194188407938856---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022800260562124537\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 7800: 0.01950755091657835---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022474043150091706\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 7900: 0.01950023881333149---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.022019748714309832\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8000: 0.019394321985932706---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.021513788564046787\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 8100: 0.019363881868204976---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.020906021395627538\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8200: 0.019166060724666412---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.021509047308252226\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8300: 0.019008015353121906---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.022755314449209085\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 8400: 0.01908646655660728---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.02490398108396933\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8500: 0.019341327524585325---Average Accuracy: 0.8782608695652175\n",
      "Error booster: 0.02735582039555392\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8600: 0.01972739853176163---Average Accuracy: 0.8717391304347827\n",
      "Error booster: 0.039587704351284746\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8700: 0.02009217196054894---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.06488939829028\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 8800: 0.02000869861620675---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.05410771499007946\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 8900: 0.01989094882754522---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.039866287838957404\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 9000: 0.019919844646893184---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.044853355619662125\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 9100: 0.019913174459797765---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.04872235752579992\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 9200: 0.01972973087888107---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.04870542717811186\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 9300: 0.01950248155681385---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.04543384867400779\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 9400: 0.019348308635620644---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.04747091294134638\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9500: 0.01926357589687849---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.05051640848974111\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9600: 0.019241638122477346---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.04888038918902649\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9700: 0.019241261005929197---Average Accuracy: 0.8869565217391302\n",
      "Error booster: 0.04551339548744328\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 9800: 0.019096414566543433---Average Accuracy: 0.8913043478260869\n",
      "Error booster: 0.041609849242535586\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 9900: 0.018814940158401794---Average Accuracy: 0.8956521739130435\n",
      "Error booster: 0.040032655677083404\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10000: 0.018377041001887164---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.04039203512296041\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10100: 0.018337468389854783---Average Accuracy: 0.8913043478260868\n",
      "Error booster: 0.04390705184952145\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10200: 0.018342818142865144---Average Accuracy: 0.8956521739130432\n",
      "Error booster: 0.04267030611542101\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10300: 0.018265730416396387---Average Accuracy: 0.9021739130434783\n",
      "Error booster: 0.04092610182076308\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 10400: 0.01815786047570376---Average Accuracy: 0.8999999999999998\n",
      "Error booster: 0.036048745773667144\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 10500: 0.018134615874200552---Average Accuracy: 0.8956521739130432\n",
      "Error booster: 0.03446549955196997\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 10600: 0.01815381284943581---Average Accuracy: 0.8913043478260869\n",
      "Error booster: 0.05101775597879319\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 10700: 0.01810388794772778---Average Accuracy: 0.893478260869565\n",
      "Error booster: 0.08001328370525371\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 10800: 0.018212121860019755---Average Accuracy: 0.8891304347826086\n",
      "Error booster: 0.07662860731967279\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Average Error epoch 10900: 0.018511658956147276---Average Accuracy: 0.8869565217391302\n",
      "Error booster: 0.06700038538590103\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11000: 0.018730445351794776---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.07210710254311603\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11100: 0.018899345635651533---Average Accuracy: 0.8913043478260869\n",
      "Error booster: 0.07335740265971463\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11200: 0.019290655750189224---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.07229842132863289\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 11300: 0.01940084225917169---Average Accuracy: 0.8804347826086955\n",
      "Error booster: 0.06972989986702477\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 11400: 0.019559732411066004---Average Accuracy: 0.876086956521739\n",
      "Error booster: 0.06847735472782872\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 11500: 0.019904760507553406---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.06825159578034418\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 11600: 0.020133939024626332---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.06794610345374368\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 11700: 0.01982781816945864---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.06920942206882166\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Average Error epoch 11800: 0.020065292223517325---Average Accuracy: 0.8760869565217391\n",
      "Error booster: 0.07737340121937611\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 11900: 0.02043994532856119---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.12689491643871748\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12000: 0.02120728585819006---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.13266890331593925\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12100: 0.021784062941716194---Average Accuracy: 0.8608695652173912\n",
      "Error booster: 0.13271687529106546\n",
      "Accuracy in test set: 0.8051948051948052\n",
      "Average Error epoch 12200: 0.02190278630262408---Average Accuracy: 0.8608695652173913\n",
      "Error booster: 0.129143587301578\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 12300: 0.0221850682136318---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.1265304025515053\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12400: 0.022190649595198095---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.12606712899670316\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12500: 0.021435891174347684---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.12256561875387964\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12600: 0.02032899530648616---Average Accuracy: 0.8717391304347825\n",
      "Error booster: 0.05773634092990463\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 12700: 0.020393159865502716---Average Accuracy: 0.8782608695652172\n",
      "Error booster: 0.06746554482925567\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 12800: 0.020372807423867288---Average Accuracy: 0.8826086956521738\n",
      "Error booster: 0.0963171703151671\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 12900: 0.01980771266166138---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.11409147857602808\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 13000: 0.019655947677557614---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.11242597500764047\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 13100: 0.01998730209690704---Average Accuracy: 0.8826086956521741\n",
      "Error booster: 0.035313790472705935\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 13200: 0.020225559854764194---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.030048425789060872\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13300: 0.019723799788152366---Average Accuracy: 0.8956521739130434\n",
      "Error booster: 0.027862320728700672\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 13400: 0.019567738843492576---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.028155734187898927\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13500: 0.018947337956757074---Average Accuracy: 0.8869565217391305\n",
      "Error booster: 0.027533685860394886\n",
      "Accuracy in test set: 0.8831168831168831\n",
      "Average Error epoch 13600: 0.019082070333948882---Average Accuracy: 0.8934782608695654\n",
      "Error booster: 0.027118557267507913\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13700: 0.019303522359585285---Average Accuracy: 0.8934782608695654\n",
      "Error booster: 0.026138995969116747\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13800: 0.019537383023831824---Average Accuracy: 0.8913043478260871\n",
      "Error booster: 0.025015618679152807\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 13900: 0.01945454726462261---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.024065485975803064\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14000: 0.019423199764001392---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.023432219017244994\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14100: 0.019378707723834054---Average Accuracy: 0.8913043478260871\n",
      "Error booster: 0.02301043493133707\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14200: 0.019347754024668245---Average Accuracy: 0.8891304347826088\n",
      "Error booster: 0.022662360422107907\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14300: 0.01954095813775701---Average Accuracy: 0.8869565217391305\n",
      "Error booster: 0.021783103537467034\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14400: 0.019630245900693587---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.020929980693936645\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14500: 0.019493135154187897---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.019981589355439876\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14600: 0.01920015568870764---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.01906099268589332\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14700: 0.019122768562395608---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.018223928651532335\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 14800: 0.019120134504141125---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.01747776520637296\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 14900: 0.019102884436643718---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.017077461773670484\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 15000: 0.019036467657420942---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.016777829302662046\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 15100: 0.01903748213751089---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.01663262412632948\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 15200: 0.019129463168520166---Average Accuracy: 0.8869565217391304\n",
      "Error booster: 0.016918853109201024\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 15300: 0.019323328723640898---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.017330148448255006\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 15400: 0.01925198219711452---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.01764295553476034\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 15500: 0.019106107231300126---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.03139539106590908\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 15600: 0.019469880418265487---Average Accuracy: 0.8804347826086955\n",
      "Error booster: 0.043853587000075196\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 15700: 0.01915840064506702---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.07149372726910437\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 15800: 0.019202210674703343---Average Accuracy: 0.8847826086956523\n",
      "Error booster: 0.030185157152680987\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 15900: 0.019184931314931958---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.03293903307589915\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 16000: 0.01923484719613806---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.032720478302762666\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 16100: 0.018929285720256237---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.03208115779061081\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16200: 0.019280139779692295---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.0408061562662751\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16300: 0.019200026038842313---Average Accuracy: 0.8934782608695653\n",
      "Error booster: 0.04120187851378992\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16400: 0.019267729940750013---Average Accuracy: 0.8891304347826087\n",
      "Error booster: 0.04236690887303817\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16500: 0.01974081591642594---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.04634941066335027\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 16600: 0.020300088429258865---Average Accuracy: 0.8804347826086957\n",
      "Error booster: 0.04952452234835604\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 16700: 0.02079305476359882---Average Accuracy: 0.8847826086956521\n",
      "Error booster: 0.11022840804830565\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 16800: 0.021104664741964266---Average Accuracy: 0.8826086956521739\n",
      "Error booster: 0.11210419032196287\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 16900: 0.021221137149820386---Average Accuracy: 0.8739130434782608\n",
      "Error booster: 0.11376069575974083\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 17000: 0.021391093651813707---Average Accuracy: 0.8652173913043477\n",
      "Error booster: 0.11740932281102512\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 17100: 0.021835308756164722---Average Accuracy: 0.8608695652173913\n",
      "Error booster: 0.12023406716061139\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 17200: 0.022197401077959---Average Accuracy: 0.8586956521739131\n",
      "Error booster: 0.11865512029727734\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 17300: 0.022651751743081934---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.1198937995562428\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 17400: 0.023352302974892637---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.15127748797524743\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 17500: 0.023743854446427074---Average Accuracy: 0.8521739130434781\n",
      "Error booster: 0.19358516630932923\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 17600: 0.0240695434511238---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.1928850021688077\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 17700: 0.023958150691763432---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.19206340434481992\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 17800: 0.023959386937713264---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.19078015644794544\n",
      "Accuracy in test set: 0.8181818181818182\n",
      "Average Error epoch 17900: 0.023844883361948278---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.18895474134403142\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 18000: 0.023939155477053574---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.18627261613125048\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 18100: 0.02398933572454144---Average Accuracy: 0.85\n",
      "Error booster: 0.18441537491937887\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 18200: 0.024303882975002782---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.1824533116462897\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 18300: 0.024812925514769314---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.18184172033177531\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 18400: 0.02486937087853349---Average Accuracy: 0.85\n",
      "Error booster: 0.1840597874765424\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 18500: 0.02493879978598971---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.18565147178443472\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 18600: 0.025230307286361737---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.18725378641321064\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 18700: 0.025416739307109856---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.18576998548911366\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 18800: 0.0258439810553242---Average Accuracy: 0.8369565217391305\n",
      "Error booster: 0.1787089178289618\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 18900: 0.0260563428149313---Average Accuracy: 0.8369565217391306\n",
      "Error booster: 0.17446787332746477\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 19000: 0.02644574337595465---Average Accuracy: 0.8391304347826086\n",
      "Error booster: 0.16765072671952103\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 19100: 0.02645153071566213---Average Accuracy: 0.8326086956521739\n",
      "Error booster: 0.15525778498704473\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 19200: 0.02621557894201356---Average Accuracy: 0.8282608695652173\n",
      "Error booster: 0.150473716738812\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 19300: 0.025970740635987498---Average Accuracy: 0.8369565217391303\n",
      "Error booster: 0.15046559972703916\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 19400: 0.025904878969929237---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.1500328400729216\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19500: 0.0256100389464566---Average Accuracy: 0.834782608695652\n",
      "Error booster: 0.14759712987196966\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19600: 0.02559808486135388---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.14620397669043209\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19700: 0.025179686698539303---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.1427254870872886\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 19800: 0.025544885408236916---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.13972454249305646\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 19900: 0.02572489700963137---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.13843743259581626\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20000: 0.02538732859130488---Average Accuracy: 0.841304347826087\n",
      "Error booster: 0.13997457956872444\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20100: 0.02518094219663699---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.14264425814835024\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20200: 0.025289707724057208---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.1255718880885193\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20300: 0.02526484347371449---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.12432650393606784\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 20400: 0.024938949301373733---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.07421422139829861\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 20500: 0.024873414303089668---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.0757431112176641\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 20600: 0.02496429106872455---Average Accuracy: 0.8543478260869565\n",
      "Error booster: 0.07636674246166467\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 20700: 0.02498869335451368---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.07624887736702098\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 20800: 0.025134873012516715---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.07399381251643436\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 20900: 0.02525512033526579---Average Accuracy: 0.8434782608695653\n",
      "Error booster: 0.07167884097803386\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21000: 0.02530383198681924---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06872970670080963\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21100: 0.02554025219276368---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.06565994171032671\n",
      "Accuracy in test set: 0.8766233766233766\n",
      "Average Error epoch 21200: 0.025698487854023688---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06111874559920477\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21300: 0.025557690600679608---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.05378260889877422\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21400: 0.02553564828961736---Average Accuracy: 0.8434782608695651\n",
      "Error booster: 0.05010065332415137\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 21500: 0.025273247900592304---Average Accuracy: 0.8456521739130433\n",
      "Error booster: 0.04914109918579819\n",
      "Accuracy in test set: 0.8701298701298701\n",
      "Average Error epoch 21600: 0.02484800758838105---Average Accuracy: 0.8413043478260869\n",
      "Error booster: 0.05461084044818439\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 21700: 0.024746676601495023---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.052329885027810816\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 21800: 0.024719370236113185---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.05083689247511669\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 21900: 0.024836116908666547---Average Accuracy: 0.85\n",
      "Error booster: 0.06286066224656274\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 22000: 0.02489569404266987---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06883818513345166\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 22100: 0.024649032159151794---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.06383294412998616\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 22200: 0.024564809892146735---Average Accuracy: 0.8499999999999999\n",
      "Error booster: 0.05884405936933508\n",
      "Accuracy in test set: 0.8116883116883117\n",
      "Average Error epoch 22300: 0.024327993807003446---Average Accuracy: 0.85\n",
      "Error booster: 0.05647609085173213\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 22400: 0.024089480235329433---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.05563692882638778\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 22500: 0.024020651275499773---Average Accuracy: 0.8630434782608695\n",
      "Error booster: 0.052738170464311326\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 22600: 0.02413817603545054---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05270051293635843\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 22700: 0.02396992076736378---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05279109059581215\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 22800: 0.023659004187245477---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05314431686889722\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 22900: 0.023475491349601068---Average Accuracy: 0.8608695652173913\n",
      "Error booster: 0.05245365151015766\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23000: 0.023318023240777794---Average Accuracy: 0.8608695652173912\n",
      "Error booster: 0.053192413730368183\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 23100: 0.02290115496782703---Average Accuracy: 0.8586956521739129\n",
      "Error booster: 0.05322817766456446\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23200: 0.022798561673759033---Average Accuracy: 0.8608695652173912\n",
      "Error booster: 0.05465586132766087\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23300: 0.02287935392235369---Average Accuracy: 0.8630434782608696\n",
      "Error booster: 0.058103210047723786\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 23400: 0.02276280379271736---Average Accuracy: 0.8565217391304347\n",
      "Error booster: 0.06131907214952561\n",
      "Accuracy in test set: 0.8636363636363636\n",
      "Average Error epoch 23500: 0.023005122198426712---Average Accuracy: 0.8586956521739131\n",
      "Error booster: 0.06623063852481172\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23600: 0.023270685158877893---Average Accuracy: 0.8543478260869566\n",
      "Error booster: 0.0775920598892613\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 23700: 0.023677121955728034---Average Accuracy: 0.8543478260869566\n",
      "Error booster: 0.08266277753539632\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 23800: 0.024283013737684024---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.08556943245575852\n",
      "Accuracy in test set: 0.8506493506493507\n",
      "Average Error epoch 23900: 0.024467210820930826---Average Accuracy: 0.8521739130434783\n",
      "Error booster: 0.08660622583332488\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 24000: 0.024540954384816852---Average Accuracy: 0.8521739130434781\n",
      "Error booster: 0.08555495209081004\n",
      "Accuracy in test set: 0.8571428571428571\n",
      "Average Error epoch 24100: 0.024782956550099714---Average Accuracy: 0.85\n",
      "Error booster: 0.08471504001472648\n",
      "Accuracy in test set: 0.8441558441558441\n",
      "Average Error epoch 24200: 0.024804184791774885---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.09042155006080131\n",
      "Accuracy in test set: 0.8376623376623377\n",
      "Average Error epoch 24300: 0.024928209875659378---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.09571470940194576\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24400: 0.024604412515928095---Average Accuracy: 0.85\n",
      "Error booster: 0.09519813690503594\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 24500: 0.024658015332466577---Average Accuracy: 0.8456521739130435\n",
      "Error booster: 0.09574219591414787\n",
      "Accuracy in test set: 0.8246753246753247\n",
      "Average Error epoch 24600: 0.02466099525711068---Average Accuracy: 0.85\n",
      "Error booster: 0.09838811109296389\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24700: 0.024727227248908745---Average Accuracy: 0.85\n",
      "Error booster: 0.10080533672688878\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24800: 0.024645961580766283---Average Accuracy: 0.8478260869565217\n",
      "Error booster: 0.1014876315990932\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 24900: 0.02471952390340635---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.10231496615593835\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Average Error epoch 25000: 0.02471625805665003---Average Accuracy: 0.8478260869565216\n",
      "Error booster: 0.10202135549430984\n",
      "Accuracy in test set: 0.8311688311688312\n",
      "Training complete!\n",
      "Validation...\n",
      "------------------------------------------------------------------\n",
      "Predictive accuracy: 0.6558441558441559\n"
     ]
    }
   ],
   "source": [
    "net1.SGD(X_train,y_train,X_test, y_test, minibatch_size)\n",
    "print(\"Validation...\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "net2.predict(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40ae9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_data = np.load(\"saved_training_data.npy\",  allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a877eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    \"\"\"Splits the generated dataset into X and y for training purposes\"\"\"\n",
    "    X = np.array([data[i][0] for i in range(len(data))])\n",
    "    y = np.array([data[i][1] for i in range(len(data))])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13071c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data(cart_data)\n",
    "\n",
    "y_t = np.argmax(y)\n",
    "y_t = []\n",
    "for i in y:\n",
    "    y_t.append(np.argmax(i))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_t), test_size=0.3, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#Scaling\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# (unique, counts) = np.unique(y_t, return_counts=True)\n",
    "# frequencies = np.asarray((unique, counts/len(y_t))).T\n",
    "# frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f73653df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes2 = [4, 128,128, 60, 2]\n",
    "EPOCHS = 30000\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = Dense(sizes2, activations = [Sigmoid(),Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 3)\n",
    "        \n",
    "net2 = Dense(sizes2, activations = [Sigmoid(),Sigmoid(), Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5e116813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum Training......\n",
      "Error epoch 100: 0.7015255029720338--- Accuracy: 0.5014\n",
      "Accuracy in test set: 0.478\n",
      "Error epoch 200: 0.6897593227633461--- Accuracy: 0.5256\n",
      "Accuracy in test set: 0.5102\n",
      "Error epoch 300: 0.6824456347942299--- Accuracy: 0.556\n",
      "Accuracy in test set: 0.5406\n",
      "Error epoch 400: 0.6785343189218118--- Accuracy: 0.5684\n",
      "Accuracy in test set: 0.5582\n",
      "Error epoch 500: 0.6769218216659857--- Accuracy: 0.5768\n",
      "Accuracy in test set: 0.5694\n",
      "Error epoch 600: 0.6751824124111878--- Accuracy: 0.5814\n",
      "Accuracy in test set: 0.5734\n",
      "Error epoch 700: 0.6736594279874627--- Accuracy: 0.5856\n",
      "Accuracy in test set: 0.5802\n",
      "Error epoch 800: 0.6724368214595765--- Accuracy: 0.587\n",
      "Accuracy in test set: 0.5818\n",
      "Error epoch 900: 0.6715526410443461--- Accuracy: 0.589\n",
      "Accuracy in test set: 0.585\n",
      "Error epoch 1000: 0.6707356861757908--- Accuracy: 0.5906\n",
      "Accuracy in test set: 0.5868\n",
      "Error epoch 1100: 0.6699406640617531--- Accuracy: 0.5922\n",
      "Accuracy in test set: 0.5886\n",
      "Error epoch 1200: 0.6692615632809606--- Accuracy: 0.592\n",
      "Accuracy in test set: 0.5874\n",
      "Error epoch 1300: 0.6687467890631098--- Accuracy: 0.597\n",
      "Accuracy in test set: 0.5886\n",
      "Error epoch 1400: 0.6682832923658294--- Accuracy: 0.5988\n",
      "Accuracy in test set: 0.5896\n",
      "Error epoch 1500: 0.6678500175999766--- Accuracy: 0.5964\n",
      "Accuracy in test set: 0.5872\n",
      "Error epoch 1600: 0.6674686928638126--- Accuracy: 0.599\n",
      "Accuracy in test set: 0.5852\n",
      "Error epoch 1700: 0.6671834057444482--- Accuracy: 0.6012\n",
      "Accuracy in test set: 0.5866\n",
      "Error epoch 1800: 0.6669483200477978--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.5888\n",
      "Error epoch 1900: 0.6667416421632942--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5896\n",
      "Error epoch 2000: 0.6665660912277864--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.5894\n",
      "Error epoch 2100: 0.6664274568247657--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.5906\n",
      "Error epoch 2200: 0.6663199238259633--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.5892\n",
      "Error epoch 2300: 0.666187887726638--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.5886\n",
      "Error epoch 2400: 0.6660730114714836--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.59\n",
      "Error epoch 2500: 0.6660076616347634--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.591\n",
      "Error epoch 2600: 0.6659514450938324--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.592\n",
      "Error epoch 2700: 0.6658881958057344--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.5908\n",
      "Error epoch 2800: 0.665794943869372--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5912\n",
      "Error epoch 2900: 0.6656941150356182--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5914\n",
      "Error epoch 3000: 0.6656109555305167--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.5936\n",
      "Error epoch 3100: 0.6655607413822421--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.591\n",
      "Error epoch 3200: 0.6655297191365189--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.5912\n",
      "Error epoch 3300: 0.6654412373782994--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.5914\n",
      "Error epoch 3400: 0.6653342213471073--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.5906\n",
      "Error epoch 3500: 0.665243789055918--- Accuracy: 0.6038\n",
      "Accuracy in test set: 0.59\n",
      "Error epoch 3600: 0.6651437828073576--- Accuracy: 0.6032\n",
      "Accuracy in test set: 0.5902\n",
      "Error epoch 3700: 0.6650699167678237--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.5908\n",
      "Error epoch 3800: 0.6650115283460937--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5902\n",
      "Error epoch 3900: 0.6649698824680585--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.5906\n",
      "Error epoch 4000: 0.6649404107754242--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.5916\n",
      "Error epoch 4100: 0.6649408298700277--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.5914\n",
      "Error epoch 4200: 0.6649396644757564--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.5926\n",
      "Error epoch 4300: 0.6649316854210012--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.5922\n",
      "Error epoch 4400: 0.6649155359558164--- Accuracy: 0.6032\n",
      "Accuracy in test set: 0.5928\n",
      "Error epoch 4500: 0.6649102494724519--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5936\n",
      "Error epoch 4600: 0.6649277391209109--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.5924\n",
      "Error epoch 4700: 0.6649497668162426--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.5928\n",
      "Error epoch 4800: 0.6649848930326049--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.5938\n",
      "Error epoch 4900: 0.66502574887512--- Accuracy: 0.6008\n",
      "Accuracy in test set: 0.5926\n",
      "Error epoch 5000: 0.6650500348289078--- Accuracy: 0.5994\n",
      "Accuracy in test set: 0.5928\n",
      "Error epoch 5100: 0.6650587824652489--- Accuracy: 0.5986\n",
      "Accuracy in test set: 0.593\n",
      "Error epoch 5200: 0.6650518383098266--- Accuracy: 0.5992\n",
      "Accuracy in test set: 0.5934\n",
      "Error epoch 5300: 0.665036947561848--- Accuracy: 0.5998\n",
      "Accuracy in test set: 0.5922\n",
      "Error epoch 5400: 0.6650251052733731--- Accuracy: 0.599\n",
      "Accuracy in test set: 0.5936\n",
      "Error epoch 5500: 0.6650244395688241--- Accuracy: 0.6\n",
      "Accuracy in test set: 0.5934\n",
      "Error epoch 5600: 0.6650384752655919--- Accuracy: 0.6006\n",
      "Accuracy in test set: 0.5928\n",
      "Error epoch 5700: 0.6650657849412017--- Accuracy: 0.6008\n",
      "Accuracy in test set: 0.5924\n",
      "Error epoch 5800: 0.6651094784978352--- Accuracy: 0.6008\n",
      "Accuracy in test set: 0.593\n",
      "Error epoch 5900: 0.6651592874597695--- Accuracy: 0.6004\n",
      "Accuracy in test set: 0.5928\n",
      "Error epoch 6000: 0.6652184266265605--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.5926\n",
      "Error epoch 6100: 0.6652882082862825--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.5918\n",
      "Error epoch 6200: 0.6653473035205556--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5932\n",
      "Error epoch 6300: 0.6654231784631743--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5932\n",
      "Error epoch 6400: 0.66550276734378--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.5932\n",
      "Error epoch 6500: 0.6655670464129032--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.5944\n",
      "Error epoch 6600: 0.6656221107066022--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.5944\n",
      "Error epoch 6700: 0.6656900322607072--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.5954\n",
      "Error epoch 6800: 0.6657555376763359--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.595\n",
      "Error epoch 6900: 0.6658236794702898--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.5946\n",
      "Error epoch 7000: 0.6658878107906874--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.5948\n",
      "Error epoch 7100: 0.6659251563035028--- Accuracy: 0.6038\n",
      "Accuracy in test set: 0.5946\n",
      "Error epoch 7200: 0.6659537167818244--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5954\n",
      "Error epoch 7300: 0.6659780972907092--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.5956\n",
      "Error epoch 7400: 0.6659751540099588--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.596\n",
      "Error epoch 7500: 0.665962731349503--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.5952\n",
      "Error epoch 7600: 0.6659571769654711--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.5962\n",
      "Error epoch 7700: 0.665963112268006--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.5974\n",
      "Error epoch 7800: 0.6659655393002281--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.5972\n",
      "Error epoch 7900: 0.6659633943005885--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.5974\n",
      "Error epoch 8000: 0.6659579590499098--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.5974\n",
      "Error epoch 8100: 0.6659513942985433--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.5978\n",
      "Error epoch 8200: 0.665966039237977--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.5974\n",
      "Error epoch 8300: 0.6659874709680407--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.5968\n",
      "Error epoch 8400: 0.6660140924765213--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.5986\n",
      "Error epoch 8500: 0.6660462879573145--- Accuracy: 0.6038\n",
      "Accuracy in test set: 0.5992\n",
      "Error epoch 8600: 0.6660892770376909--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.5996\n",
      "Error epoch 8700: 0.6661167311696896--- Accuracy: 0.6032\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 8800: 0.6661436677270377--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.5994\n",
      "Error epoch 8900: 0.6661775560411161--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 9000: 0.6662050813621351--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.5994\n",
      "Error epoch 9100: 0.6662366901985586--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 9200: 0.6662774205550835--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 9300: 0.6663155131975577--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 9400: 0.6663506828464457--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 9500: 0.666377445488412--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5996\n",
      "Error epoch 9600: 0.6664023194182511--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5992\n",
      "Error epoch 9700: 0.6664194157712994--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.5996\n",
      "Error epoch 9800: 0.66642405151954--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.5988\n",
      "Error epoch 9900: 0.6664198345039369--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 10000: 0.6664243384216841--- Accuracy: 0.6038\n",
      "Accuracy in test set: 0.5996\n",
      "Error epoch 10100: 0.6664336945509062--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 10200: 0.6664365131845427--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6004\n",
      "Error epoch 10300: 0.6664299606263678--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.6004\n",
      "Error epoch 10400: 0.6664219536810883--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 10500: 0.6664153358518653--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 10600: 0.6664129725549784--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 10700: 0.6664161261469198--- Accuracy: 0.6008\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 10800: 0.6664262896345509--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6014\n",
      "Error epoch 10900: 0.6664310659828053--- Accuracy: 0.6012\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 11000: 0.6664336217801518--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 11100: 0.6664520355055192--- Accuracy: 0.5998\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 11200: 0.6664719177436642--- Accuracy: 0.6006\n",
      "Accuracy in test set: 0.6026\n",
      "Error epoch 11300: 0.6664864521475355--- Accuracy: 0.6004\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 11400: 0.6664947934586901--- Accuracy: 0.601\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 11500: 0.6664895364221021--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 11600: 0.6664817229985002--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 11700: 0.6664784952965938--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.605\n",
      "Error epoch 11800: 0.6664715473749178--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 11900: 0.666447715919939--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 12000: 0.6664266528215762--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 12100: 0.6664100171568698--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 12200: 0.6663892234259141--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 12300: 0.6663811674015421--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 12400: 0.6663808565543093--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 12500: 0.6663826157616323--- Accuracy: 0.6012\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 12600: 0.6663666598299584--- Accuracy: 0.6008\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 12700: 0.6663503596862732--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 12800: 0.6663327009424567--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 12900: 0.6662935679039965--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 13000: 0.6662390380528818--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 13100: 0.6661791206270568--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 13200: 0.6661125819458502--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 13300: 0.6660204892500131--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6028\n",
      "Error epoch 13400: 0.6659184217577018--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 13500: 0.665813702962864--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6026\n",
      "Error epoch 13600: 0.66572158483653--- Accuracy: 0.6012\n",
      "Accuracy in test set: 0.6022\n",
      "Error epoch 13700: 0.6656469663526164--- Accuracy: 0.6012\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 13800: 0.66557366669078--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 13900: 0.6654926268298029--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 14000: 0.6654153784477815--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 14100: 0.6653340460346137--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 14200: 0.6652622564634723--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.6004\n",
      "Error epoch 14300: 0.6651933415949909--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 14400: 0.6651401075462187--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 14500: 0.6651016400279041--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 14600: 0.6650515646205074--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 14700: 0.6649970241904262--- Accuracy: 0.6032\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 14800: 0.6649535095262021--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 14900: 0.6649176819559793--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 15000: 0.6648970471777819--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 15100: 0.664876261908734--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 15200: 0.6648571117325371--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 15300: 0.6648366842282963--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 15400: 0.6648295495002724--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.6022\n",
      "Error epoch 15500: 0.6648354824390028--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 15600: 0.6648374805356674--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 15700: 0.6648291243662671--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 15800: 0.6648118424583503--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 15900: 0.6647825087594369--- Accuracy: 0.6012\n",
      "Accuracy in test set: 0.6026\n",
      "Error epoch 16000: 0.6647447862518715--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.6028\n",
      "Error epoch 16100: 0.6647063705611747--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 16200: 0.6646750708129945--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6014\n",
      "Error epoch 16300: 0.6646397685653276--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 16400: 0.6646056732904393--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 16500: 0.6645852271822578--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 16600: 0.6645771767681901--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 16700: 0.6645716537684099--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5996\n",
      "Error epoch 16800: 0.6645658017182071--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.5988\n",
      "Error epoch 16900: 0.6645592235383234--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.5994\n",
      "Error epoch 17000: 0.6645716203173926--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.5988\n",
      "Error epoch 17100: 0.6645914793044564--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.5988\n",
      "Error epoch 17200: 0.6646120409851112--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 17300: 0.6646296269727081--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6004\n",
      "Error epoch 17400: 0.6646502522140271--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 17500: 0.6646643001573184--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 17600: 0.6646776793037856--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 17700: 0.6646885136798888--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 17800: 0.6647071215658952--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.5992\n",
      "Error epoch 17900: 0.6647293236887415--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.5992\n",
      "Error epoch 18000: 0.6647618930193393--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.599\n",
      "Error epoch 18100: 0.6647957205958778--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.5992\n",
      "Error epoch 18200: 0.6648364321775143--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 18300: 0.6648750475872677--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.5988\n",
      "Error epoch 18400: 0.6649184806527727--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.599\n",
      "Error epoch 18500: 0.6649584766205038--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5992\n",
      "Error epoch 18600: 0.6650019202608864--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.5996\n",
      "Error epoch 18700: 0.6650397943840994--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6004\n",
      "Error epoch 18800: 0.6650704074136141--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 18900: 0.6650965386441894--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.601\n",
      "Error epoch 19000: 0.6651155623212661--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 19100: 0.6651205747336336--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6004\n",
      "Error epoch 19200: 0.6651184939404446--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 19300: 0.6651175876148137--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 19400: 0.6651109613258667--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 19500: 0.6651055225485929--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6014\n",
      "Error epoch 19600: 0.6651021798279032--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 19700: 0.6650858516591206--- Accuracy: 0.6032\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 19800: 0.6650637596315968--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 19900: 0.6650386302513572--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 20000: 0.6650205443633757--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 20100: 0.6649989724297748--- Accuracy: 0.6028\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 20200: 0.6649750117615321--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 20300: 0.6649442519152734--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 20400: 0.66490807897754--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 20500: 0.664877783174093--- Accuracy: 0.6034\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 20600: 0.6648486879225698--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 20700: 0.6648147980937933--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 20800: 0.6647852384162397--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 20900: 0.6647593677784602--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 21000: 0.6647327381338555--- Accuracy: 0.6062\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 21100: 0.6647024451150491--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 21200: 0.6646857606824167--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 21300: 0.6646688276067573--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 21400: 0.6646438081940381--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 21500: 0.6646146881269801--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 21600: 0.6645963792491684--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6022\n",
      "Error epoch 21700: 0.6645788365680041--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 21800: 0.6645499814761783--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 21900: 0.6645200111086891--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 22000: 0.664475525730536--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 22100: 0.6644252287188143--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 22200: 0.6643756444420076--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 22300: 0.6643207485229891--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 22400: 0.6642610179672621--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 22500: 0.6642071858123187--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.605\n",
      "Error epoch 22600: 0.6641651964187324--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 22700: 0.6641251370573891--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 22800: 0.6640931127180716--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 22900: 0.6640590565990615--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 23000: 0.664024475674015--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.605\n",
      "Error epoch 23100: 0.663990422821882--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 23200: 0.6639503860970573--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.605\n",
      "Error epoch 23300: 0.6639119106156552--- Accuracy: 0.6046\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 23400: 0.6638715332542295--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 23500: 0.6638381589443496--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 23600: 0.6638076780889379--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 23700: 0.6637775211246785--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 23800: 0.6637450167427048--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 23900: 0.6637125215596453--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 24000: 0.6636833600411605--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 24100: 0.6636569408645411--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 24200: 0.6636314085704617--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 24300: 0.6635975025136087--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 24400: 0.6635608768163113--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 24500: 0.6635238516465161--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 24600: 0.663495959467888--- Accuracy: 0.6078\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 24700: 0.6634782796313013--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 24800: 0.6634640566997583--- Accuracy: 0.6078\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 24900: 0.66345727056174--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 25000: 0.663455583852166--- Accuracy: 0.6078\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 25100: 0.6634476830017404--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 25200: 0.6634386986914456--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 25300: 0.6634295314148645--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 25400: 0.6634226147434884--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 25500: 0.6634230655710788--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 25600: 0.6634327319425087--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 25700: 0.6634481322590134--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 25800: 0.6634708895904262--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 25900: 0.6634984891547422--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 26000: 0.6635201540754011--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 26100: 0.6635356852141662--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 26200: 0.6635519001890926--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 26300: 0.6635720469331172--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 26400: 0.6635899202090512--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 26500: 0.663606575953847--- Accuracy: 0.6084\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 26600: 0.6636301994273149--- Accuracy: 0.6088\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 26700: 0.6636537075938722--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 26800: 0.6636791275732455--- Accuracy: 0.6088\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 26900: 0.6637086855153078--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 27000: 0.6637291792708382--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 27100: 0.6637405037867913--- Accuracy: 0.6084\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 27200: 0.663738148357339--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 27300: 0.6637242542535352--- Accuracy: 0.6066\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 27400: 0.663714577757485--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 27500: 0.6637024078538433--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 27600: 0.6636841484936438--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.6022\n",
      "Error epoch 27700: 0.6636667012768008--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 27800: 0.6636529628159762--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 27900: 0.6636349453300272--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 28000: 0.6636119905228679--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 28100: 0.6636006484945647--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 28200: 0.6635991724818314--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 28300: 0.6636002502457186--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 28400: 0.6636028212150364--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 28500: 0.6635959835565812--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 28600: 0.6635983918209345--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 28700: 0.6635859179655111--- Accuracy: 0.6066\n",
      "Accuracy in test set: 0.6038\n",
      "Error epoch 28800: 0.6635692024875743--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 28900: 0.663539718068744--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 29000: 0.6635075331937638--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 29100: 0.6634693365050278--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 29200: 0.6634203876877717--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 29300: 0.6633698918528096--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.6028\n",
      "Error epoch 29400: 0.6633121683345984--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.603\n",
      "Error epoch 29500: 0.6632486642079756--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6032\n",
      "Error epoch 29600: 0.6631794506400771--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6026\n",
      "Error epoch 29700: 0.6631235289623602--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6022\n",
      "Error epoch 29800: 0.6630725209161765--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 29900: 0.6630245127033725--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6014\n",
      "Error epoch 30000: 0.6629931122720655--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6014\n",
      "Initial loss: 0.9891313688636606\n",
      "Final loss after 30000 iterations: 0.6629931122720655\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "nr = 5000\n",
    "net2.MomentumGD(X_train[:nr],y_train[:nr],X_test[:nr], y_test[:nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "235014d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive accuracy: 0.5971098104013218\n"
     ]
    }
   ],
   "source": [
    "net2.predict(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d07d583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###SAVING THE PARAMETERS FOR TRANSFER LEARNING PROJECTS\n",
    "trained_weights = net2.weights\n",
    "trained_biases = net2.biases\n",
    "\n",
    "\n",
    "\n",
    "import  pickle\n",
    "\n",
    "with open('mat.pkl', 'wb') as outfile:\n",
    "    pickle.dump(trained_weights, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('mat.pkl', 'rb') as infile:\n",
    "    result_weights= pickle.load(infile)\n",
    "\n",
    "\n",
    "\n",
    "with open('mat.pkl', 'wb') as outfile:\n",
    "    pickle.dump(trained_biases, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('mat.pkl', 'rb') as infile:\n",
    "    result_biases= pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c10de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransfer():\n",
    "\n",
    "    def __init__(self, sizes, weights, biases, activations, Loss, epochs, metric, learning_rate):\n",
    "        self.weights = weights\n",
    "        self.biases =  biases\n",
    "        self.activations = activations\n",
    "        self.Loss = Loss\n",
    "        self.epochs = epochs\n",
    "        self.metric = metric\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        self.activated_layers = [x]\n",
    "        for w,b, act in zip(self.weights, self.biases, self.activations):\n",
    "            activation = act.activate(np.dot(x, w.T) + b)\n",
    "            self.activated_layers.append(activation)\n",
    "            x = activation\n",
    "            \n",
    "            \n",
    "    def backpropagate(self, y):\n",
    "        #Input: activated_layers\n",
    "        #output: Container Gradient dE/dw \n",
    "        #Initialize\n",
    "        sigmas_box = []\n",
    "        sigma_prime_box = []\n",
    "    \n",
    "       #Backprop the error ()\n",
    "        #1. Compute output layer sigma\n",
    "        loss_grad = self.Loss.loss_gradient(self.activated_layers[-1], y)\n",
    "        output_sigma = self.activations[-1].output_layer_sigma(loss_grad, self.activated_layers[-1])\n",
    "        sigmas_box = [output_sigma]\n",
    "        #Sigmas of the rest of layers...\n",
    "        for w,a,o_layer in zip(self.weights[::-1], self.activations[:-1][::-1],self.activated_layers[:-1][::-1]) :\n",
    "            sigmas_box.append(np.dot(sigmas_box[-1], w) * a.sigma_prime(o_layer))\n",
    "       \n",
    "        #Reverse sigma_box    \n",
    "        sigmas_box.reverse()\n",
    "        #Biases update\n",
    "        self.grad_biases = sigmas_box\n",
    "        #Gradient (dE/dw):\n",
    "        self.gradients = []\n",
    "        for a, s in zip(self.activated_layers[:-1], sigmas_box):\n",
    "            self.gradients.append(np.dot(s.T, a))\n",
    "        #Nota: al hacerse la multiplicacion de todos los inputs a la vez\n",
    "        #Igual se mantiene el shape de cada weight pero mientras más\n",
    "        #Inputs más grandes salen los valores de cada componente de la matriz\n",
    "        #Por eso después se divide cada weight por el total de inputs (mean)\n",
    "        # print(\"Gradients shapes:\")\n",
    "        # for g in gradients:\n",
    "        #     print(g.shape)\n",
    "       \n",
    "\n",
    "    def weight_update(self):\n",
    "        for w,gw, b, gb in zip(self.weights, self.gradients, self.biases, self.grad_biases):\n",
    "            w -= (self.learning_rate / len(X))* gw\n",
    "            b -= (self.learning_rate / len(gb))* np.sum(gb, axis= 0)\n",
    "\n",
    "        return self.weights, self.biases\n",
    "        \n",
    "    \n",
    "    def predict(self, X,y):\n",
    "            self.forward(X)\n",
    "            self.prediction = self.activated_layers[-1]\n",
    "            #Compute the accuracy\n",
    "            acc = self.metric.get_accuracy(self.prediction, y)\n",
    "            print(\"Predictive accuracy:\", acc)\n",
    "\n",
    "\n",
    "            \n",
    "    def SGD(self, X,y,x_test, y_test, minibatch_size):\n",
    "        \"\"\"Vectorized version of Minibatch Stochastic Gradient Descent\"\"\"\n",
    "        print(\"Minibatch SGD Training......\")\n",
    "        Losses = [] #saves the loss of each epoch\n",
    "        for e in range(1, self.epochs + 1):\n",
    "            #tomar dataset y generar minibatches box\n",
    "            minibatches = self.minibatch_generator(X,y, minibatch_size)\n",
    "            Accuracies = []\n",
    "            for mb in minibatches:\n",
    "                input = mb[0]\n",
    "                y_true = np.array(mb[1]).astype(int)\n",
    "                #Obtener los gradientes del minibatch usando backprop\n",
    "                self.forward(input)\n",
    "                self.backpropagate(y_true)\n",
    "                delta_nw = self.gradients #dC/dw\n",
    "                delta_nb = self.grad_biases #dC/db\n",
    "                #Updating the parameters \n",
    "                self.weights = [w - (self.learning_rate/ len(mb)) * dw for w,dw in zip(self.weights, delta_nw)]\n",
    "                self.biases = [b - (self.learning_rate/ len(mb)) * np.sum(db, axis = 0) for b, db in zip(self.biases, delta_nb)]\n",
    "            \n",
    "            #Reporte de error y accuracy por epoch...\n",
    "            #Para evaluar como va se calcula el error del epoch usando todo el dataset como corresponde\n",
    "            self.forward(X)\n",
    "            y_output = self.activated_layers[-1]\n",
    "            error = self.Loss.forward_loss(y_output, y)\n",
    "            acc = self.metric.get_accuracy(y_output, y)\n",
    "            Losses.append(error)\n",
    "\n",
    "            if (e % 100 == 0 ) or (e == self.epochs):\n",
    "                print(\"Error epoch {0}: {1}--- Accuracy: {2}\".format(e, error, acc))\n",
    "                print(\"Accuracy in test set:\", self.evaluate_test(x_test, y_test))\n",
    "        #Plotting\n",
    "        x_label = np.arange(1, self.epochs +1)\n",
    "        plt.plot(x_label, Losses)\n",
    "        plt.show()\n",
    "                   \n",
    "        print(\"Training complete!\")         \n",
    "\n",
    "\n",
    "    def MomentumGD(self, X,y,x_test, y_test, beta = 0.9):\n",
    "        \"\"\"Vectorized version\"\"\"\n",
    "        print(\"Momentum Training......\")\n",
    "        #Parameters initialization\n",
    "        #Velocities initialization\n",
    "        Vdw = [np.zeros(w.shape) for w in self.weights]\n",
    "        Vdb = [np.zeros(b.shape) for b in self.biases]\n",
    "        Losses = []\n",
    "        Accuracies = []\n",
    "        for e in range(1, self.epochs + 1):\n",
    "                self.forward(X)\n",
    "                #Calcular el error\n",
    "                error = self.Loss.forward_loss(self.activated_layers[-1], y)\n",
    "                acc = self.metric.get_accuracy(self.activated_layers[-1], y)\n",
    "                #Guardar el error y accuracy\n",
    "                Losses.append(error)\n",
    "                Accuracies.append(acc)\n",
    "                #Obtener los gradientes respectivos usando backprop\n",
    "                self.backpropagate(y)\n",
    "                delta_nw = self.gradients #dC/dw\n",
    "                delta_nb = self.grad_biases #dC/db\n",
    "                \n",
    "                #Compute the exp moving averages (velocities)\n",
    "                Vdw = [beta * vw + self.learning_rate * dnw for vw, dnw in zip(Vdw, delta_nw)]\n",
    "                Vdb = [beta * vb +  self.learning_rate * dnb.mean() for vb, dnb in zip(Vdb, delta_nb)]\n",
    "                \n",
    "                #Update weights and biases using the Velocities\n",
    "                \n",
    "                self.weights = [w - vdw for w,vdw in zip(self.weights, Vdw)]\n",
    "                self.biases = [b - vdb for b, vdb in zip(self.biases, Vdb)]\n",
    "                ''' print(\"Weights shapes:\")\n",
    "                for w in self.weights:\n",
    "                    print(w.shape)\n",
    "                print(\"Biases shapes:\")\n",
    "                for b in self.biases:\n",
    "                    print(b.shape) '''\n",
    "\n",
    "            #Reporte de error y accuracy por epoch...\n",
    "\n",
    "                if (e % 100 == 0 ) or (e == self.epochs):\n",
    "                    print(\"Error epoch {0}: {1}--- Accuracy: {2}\".format(e, error, acc))\n",
    "                    print(\"Accuracy in test set:\", self.evaluate_test(x_test, y_test))\n",
    "        \n",
    "        ##Plotting cost\n",
    "        print(\"Initial loss:\", Losses[1])\n",
    "        print(\"Final loss after {0} iterations: {1}\".format(self.epochs, Losses[-1]))\n",
    "        #Plotting\n",
    "        x_label = np.arange(1, self.epochs +1)\n",
    "        plt.plot(x_label, Losses)\n",
    "        plt.show()\n",
    "                   \n",
    "        print(\"Training complete!\") \n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "    def minibatch_generator(self, X,y, batch_size):\n",
    "        \"\"\"\"Generates minibatches with no replacement\"\"\"\n",
    "        dataset = list(zip(X,np.array(y)))\n",
    "        np.random.shuffle(dataset)\n",
    "        minibatches = [(X[i:i+batch_size], y[i:i+batch_size]) for\n",
    "                        i in range(0, len(y), batch_size)]\n",
    "                        \n",
    "        #si minibatch final es mas chico que el batch size se le mete desde\n",
    "        #atras inputs hasta completar el tamaño batch size\n",
    "        if len(minibatches[-1][0]) < batch_size:\n",
    "            minibatches[-1] = (X[-batch_size:], y[-batch_size:])\n",
    "            \n",
    "        return minibatches\n",
    "    \n",
    "    def evaluate_test(self, x_test, y_test):\n",
    "        \"\"\"Evaluates the model on the test set\n",
    "        input: x_test, y_test\n",
    "        output: accuracy\"\"\"\n",
    "        #Forward pass---obtain prediction y_pred\n",
    "        self.forward(x_test)\n",
    "        #Evaluate prediction with accuracy\n",
    "        acc_test = self.metric.get_accuracy(self.activated_layers[-1], y_test)\n",
    "        #Return accuracy\n",
    "        return acc_test\n",
    "\n",
    "        \n",
    " \n",
    "class Relu():\n",
    "    def activate(self, x):\n",
    "        self.output = np.maximum(0,x)\n",
    "        return self.output\n",
    "    \n",
    "    def sigma_prime(self, x):\n",
    "        return 1. * (x > 0)\n",
    "\n",
    "\n",
    "class Sigmoid():\n",
    "    def activate(self, x):\n",
    "        #np.exp - (x - np.max(x, axis = 1, keepdims= True))\n",
    "        x = np.clip(x, 1e-7, 1 - 1e-7)\n",
    "        self.output = 1 / (1+ np.exp (- (x - np.max(x, axis = 1, keepdims= True))))\n",
    "        #self.output = 1 / (1+ np.exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def output_layer_sigma(self, loss_gradients, x):\n",
    "        \"\"\"en realidad calcula todo el sigma de una vez como dC/da * sigma_prime\n",
    "        dC/da = loss_gradient\"\"\"\n",
    "        \n",
    "        self.output_sigma = loss_gradients * self.sigma_prime(x)\n",
    "        return self.output_sigma\n",
    "    \n",
    "    def sigma_prime(self, x):\n",
    "        return x * (1-x)\n",
    "\n",
    "class Softmax():\n",
    "    def activate(self, x):\n",
    "        #Get unnormalized probs\n",
    "        exp_values = np.exp(x - np.max(x, axis = 1, keepdims= True))\n",
    "        #Get normalized probs\n",
    "        self.output = exp_values / np.sum(exp_values, axis= 1, keepdims= True)\n",
    "        return self.output\n",
    "    \n",
    "    def output_layer_sigma(self, loss_gradients, out_activations):\n",
    "        \"\"\"Dado que es complejo multplicar el jacobiano de cada input por\n",
    "        #su loss_gradient por que el jac es una matrix, se hace aca todo directo y se saca \n",
    "        #el output layer sigma = dE/dsigma.dsigma/dz\"\"\"\n",
    "        #Se crea un contenedor donde irá el output_sigma de cada input\n",
    "        #del tamaño del loss_gradient (dinputs)\n",
    "        self.output_sigma = np.empty_like(loss_gradients)\n",
    "\n",
    "        #Tomo uno a uno los Loss_gradientes de cada input y cada\n",
    "        #softmax activation de la output layer para hacer uno a uno los\n",
    "        #output_sigmas...\n",
    "        for index, (single_act, single_loss_grad) in enumerate(zip(out_activations, loss_gradients)):\n",
    "            single_act = single_act.reshape(-1,1)\n",
    "            #Calculate jacobian matrix (sigma_prime of softmax)\n",
    "            jacobian_matrix = np.diagflat(single_act) - np.dot(single_act, single_act.T)\n",
    "            self.output_sigma[index] = np.dot(jacobian_matrix, single_loss_grad)\n",
    "        return self.output_sigma\n",
    "\n",
    "         \n",
    "\n",
    "    \n",
    "##Loss Units\n",
    "class MSE():\n",
    "    \n",
    "    #Forward\n",
    "    def forward_loss(self, y_pred, y_true):\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        labels = len(y_pred[0])                  \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        #return  np.sum((y_pred- y_true)**2, axis=1) / len(y_pred)\n",
    "        return ((y_pred- y_true)**2).mean()\n",
    "        \n",
    "    #Derivative\n",
    "    def loss_gradient(self, y_pred, y_true): #dE/dact\n",
    "        y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        labels = len(y_pred[0])                  \n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        self.dinputs = (2/len(y_pred)) * (y_pred - y_true)\n",
    "        return self.dinputs\n",
    "    \n",
    "    \n",
    "class CategoricalCrossEntropyLoss():\n",
    "    def forward_loss(self, y_pred, y_true):\n",
    "         #entrega el vector de negative losses de cada sample\n",
    "         y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7) #recorta para evitar logs mulas\n",
    "         if len(y_true.shape) == 1: #si el y_true viene en un solo vector de escalares\n",
    "             #extraigo el valor que tiene el indice indicado en el y_true\n",
    "             #correspondiente\n",
    "             correct_confidences = y_pred[range(len(y_pred)), y_true]\n",
    "        \n",
    "         if len(y_true.shape) == 2: #matrix\n",
    "             #lo mismo pero multiplique y sume para obtener el valor\n",
    "             #que tiene el indice indicado por el y_true (el resto se hace zero\n",
    "             #al multiplicar)\n",
    "             correct_confidences = np.sum( y_pred * y_true, axis = 1)\n",
    "        \n",
    "         negative_loss_likehoods = -np.log(correct_confidences)\n",
    "\n",
    "         return np.mean(negative_loss_likehoods)\n",
    "    \n",
    "    def loss_gradient(self, dvalues, y_true): #dE/dact\n",
    "        # Number of samples\n",
    "        dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "        return self.dinputs\n",
    "\n",
    "\n",
    "\n",
    "class Accuracy():\n",
    "#gets the accuracy of the training stage\n",
    "    def get_accuracy(self, y_pred, y_true):\n",
    "        #saca el indice donde esta el valor mas grande\n",
    "        predictions = np.argmax(y_pred, axis= 1)\n",
    "\n",
    "        #y_true en formato escalares\n",
    "        if len(y_true.shape) == 1:\n",
    "            accuracy = np.mean(predictions == y_true)\n",
    "        #matrix\n",
    "        elif len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis= 1)\n",
    "            accuracy = np.mean(predictions == y_true) #promedia coincidencias de valor de indice\n",
    "\n",
    "        return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "675b492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Testing transfer learning engine\n",
    "sizes2 = [4, 128,128, 60, 2]\n",
    "EPOCHS = 20000\n",
    "minibatch_size = 10\n",
    "\n",
    "net1 = DenseTransfer(sizes2, trained_weights, trained_biases, activations = [Sigmoid(),Sigmoid(), Softmax()], Loss = MSE(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 3)\n",
    "        \n",
    "net2 = DenseTransfer(sizes2, trained_weights, trained_biases, activations = [Sigmoid(),Sigmoid(), Sigmoid(), Softmax()], Loss = CategoricalCrossEntropyLoss(),\n",
    "            epochs = EPOCHS, metric = Accuracy(), learning_rate = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bc89dd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum Training......\n",
      "Error epoch 100: 0.6620954079466658--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.5934\n",
      "Error epoch 200: 0.6615583161762326--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.5946\n",
      "Error epoch 300: 0.6645085426745311--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 400: 0.6650242986450349--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 500: 0.665864572589857--- Accuracy: 0.6018\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 600: 0.6646715180164212--- Accuracy: 0.5978\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 700: 0.6624233224962278--- Accuracy: 0.6084\n",
      "Accuracy in test set: 0.6028\n",
      "Error epoch 800: 0.6626231811207818--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.5988\n",
      "Error epoch 900: 0.66448122601824--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.606\n",
      "Error epoch 1000: 0.6652966289915389--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.6008\n",
      "Error epoch 1100: 0.6674281397130051--- Accuracy: 0.5986\n",
      "Accuracy in test set: 0.5962\n",
      "Error epoch 1200: 0.6642686151252021--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 1300: 0.6638454531410193--- Accuracy: 0.6066\n",
      "Accuracy in test set: 0.601\n",
      "Error epoch 1400: 0.6640636443264147--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.607\n",
      "Error epoch 1500: 0.6635559832488825--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 1600: 0.6631571124563448--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.6042\n",
      "Error epoch 1700: 0.6629803488769126--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 1800: 0.6636654116442251--- Accuracy: 0.6058\n",
      "Accuracy in test set: 0.602\n",
      "Error epoch 1900: 0.6643966700446875--- Accuracy: 0.604\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 2000: 0.6647452742667543--- Accuracy: 0.601\n",
      "Accuracy in test set: 0.6034\n",
      "Error epoch 2100: 0.6648297816963529--- Accuracy: 0.5994\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 2200: 0.6635693136454424--- Accuracy: 0.602\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 2300: 0.6636288247315987--- Accuracy: 0.6024\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 2400: 0.6634910719359323--- Accuracy: 0.6026\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 2500: 0.6631288666799041--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5978\n",
      "Error epoch 2600: 0.6629140162105821--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.5964\n",
      "Error epoch 2700: 0.6629779982526532--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.597\n",
      "Error epoch 2800: 0.6631276201212369--- Accuracy: 0.6014\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 2900: 0.6626846076445698--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 3000: 0.662880118256541--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.6024\n",
      "Error epoch 3100: 0.6620962878273494--- Accuracy: 0.6062\n",
      "Accuracy in test set: 0.6012\n",
      "Error epoch 3200: 0.6628343494270194--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 3300: 0.662663856630937--- Accuracy: 0.6086\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 3400: 0.6625005791074345--- Accuracy: 0.6036\n",
      "Accuracy in test set: 0.6026\n",
      "Error epoch 3500: 0.6621083929623813--- Accuracy: 0.6032\n",
      "Accuracy in test set: 0.5982\n",
      "Error epoch 3600: 0.661838006417963--- Accuracy: 0.603\n",
      "Accuracy in test set: 0.6084\n",
      "Error epoch 3700: 0.6619127129725071--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6074\n",
      "Error epoch 3800: 0.6612519963380566--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.6098\n",
      "Error epoch 3900: 0.6608990230815646--- Accuracy: 0.6116\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 4000: 0.6608705428817667--- Accuracy: 0.6102\n",
      "Accuracy in test set: 0.5998\n",
      "Error epoch 4100: 0.6613897137598141--- Accuracy: 0.6074\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 4200: 0.6616084753693462--- Accuracy: 0.6022\n",
      "Accuracy in test set: 0.6006\n",
      "Error epoch 4300: 0.6622343517016592--- Accuracy: 0.6008\n",
      "Accuracy in test set: 0.6036\n",
      "Error epoch 4400: 0.6616177454822908--- Accuracy: 0.6042\n",
      "Accuracy in test set: 0.604\n",
      "Error epoch 4500: 0.6620335395221476--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.6018\n",
      "Error epoch 4600: 0.6621193198754487--- Accuracy: 0.6084\n",
      "Accuracy in test set: 0.6016\n",
      "Error epoch 4700: 0.661945037682635--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.5986\n",
      "Error epoch 4800: 0.6617801951762998--- Accuracy: 0.6048\n",
      "Accuracy in test set: 0.5954\n",
      "Error epoch 4900: 0.6634452072958671--- Accuracy: 0.6066\n",
      "Accuracy in test set: 0.597\n",
      "Error epoch 5000: 0.6622997903178559--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.5986\n",
      "Error epoch 5100: 0.6635253800809198--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 5200: 0.6649595765901221--- Accuracy: 0.6062\n",
      "Accuracy in test set: 0.6\n",
      "Error epoch 5300: 0.6663864057317757--- Accuracy: 0.6076\n",
      "Accuracy in test set: 0.6076\n",
      "Error epoch 5400: 0.6674400254507522--- Accuracy: 0.6016\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 5500: 0.6677772979178673--- Accuracy: 0.6052\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 5600: 0.6658735760738692--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 5700: 0.6654813964010725--- Accuracy: 0.6064\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 5800: 0.6661281493931834--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.607\n",
      "Error epoch 5900: 0.6656554496082463--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 6000: 0.6653881581280346--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.6072\n",
      "Error epoch 6100: 0.6653980021968148--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 6200: 0.665191231579834--- Accuracy: 0.6054\n",
      "Accuracy in test set: 0.607\n",
      "Error epoch 6300: 0.6653018245140403--- Accuracy: 0.606\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 6400: 0.6653400962115956--- Accuracy: 0.6068\n",
      "Accuracy in test set: 0.6084\n",
      "Error epoch 6500: 0.6647770615205962--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.6068\n",
      "Error epoch 6600: 0.6652213009555853--- Accuracy: 0.6044\n",
      "Accuracy in test set: 0.6026\n",
      "Error epoch 6700: 0.6662554768750621--- Accuracy: 0.6056\n",
      "Accuracy in test set: 0.6002\n",
      "Error epoch 6800: 0.6659047176363524--- Accuracy: 0.6084\n",
      "Accuracy in test set: 0.5994\n",
      "Error epoch 6900: 0.6664038602260247--- Accuracy: 0.6084\n",
      "Accuracy in test set: 0.601\n",
      "Error epoch 7000: 0.6664653089890558--- Accuracy: 0.609\n",
      "Accuracy in test set: 0.605\n",
      "Error epoch 7100: 0.6660365494543159--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 7200: 0.6660902247007683--- Accuracy: 0.61\n",
      "Accuracy in test set: 0.6046\n",
      "Error epoch 7300: 0.6659631653863678--- Accuracy: 0.611\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 7400: 0.666294456018041--- Accuracy: 0.6104\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 7500: 0.6665861435556056--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6094\n",
      "Error epoch 7600: 0.6668870382065251--- Accuracy: 0.605\n",
      "Accuracy in test set: 0.6112\n",
      "Error epoch 7700: 0.6673211531857359--- Accuracy: 0.6078\n",
      "Accuracy in test set: 0.6098\n",
      "Error epoch 7800: 0.6672897450213694--- Accuracy: 0.6106\n",
      "Accuracy in test set: 0.6094\n",
      "Error epoch 7900: 0.6672702158164133--- Accuracy: 0.6132\n",
      "Accuracy in test set: 0.6086\n",
      "Error epoch 8000: 0.667081424071842--- Accuracy: 0.6106\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 8100: 0.6667524599062407--- Accuracy: 0.6122\n",
      "Accuracy in test set: 0.607\n",
      "Error epoch 8200: 0.6669121002056799--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6072\n",
      "Error epoch 8300: 0.6669767695305623--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.6068\n",
      "Error epoch 8400: 0.6671896545741978--- Accuracy: 0.6104\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 8500: 0.6672179494290098--- Accuracy: 0.6108\n",
      "Accuracy in test set: 0.6066\n",
      "Error epoch 8600: 0.6674079814322005--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.607\n",
      "Error epoch 8700: 0.6674723647480683--- Accuracy: 0.6094\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 8800: 0.6673279526880551--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 8900: 0.6675164956932126--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 9000: 0.6675994121602257--- Accuracy: 0.6086\n",
      "Accuracy in test set: 0.6068\n",
      "Error epoch 9100: 0.6678313751921023--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.606\n",
      "Error epoch 9200: 0.6694269102073198--- Accuracy: 0.6096\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 9300: 0.6693695042805295--- Accuracy: 0.6078\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 9400: 0.6689029056911986--- Accuracy: 0.607\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 9500: 0.668139544816894--- Accuracy: 0.6072\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 9600: 0.6682249431575429--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 9700: 0.6680324329052977--- Accuracy: 0.6104\n",
      "Accuracy in test set: 0.606\n",
      "Error epoch 9800: 0.6678783539173279--- Accuracy: 0.6096\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 9900: 0.6677696149058566--- Accuracy: 0.6094\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 10000: 0.667816802595465--- Accuracy: 0.6108\n",
      "Accuracy in test set: 0.6064\n",
      "Initial loss: 0.6629906485477597\n",
      "Final loss after 10000 iterations: 0.667816802595465\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "nr = 5000\n",
    "net2.MomentumGD(X_train[:nr],y_train[:nr],X_test[:nr], y_test[:nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1daf0d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Momentum Training......\n",
      "Error epoch 100: 0.6678560485131635--- Accuracy: 0.6088\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 200: 0.6681114792151253--- Accuracy: 0.608\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 300: 0.6682995470979187--- Accuracy: 0.6086\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 400: 0.6678223245285926--- Accuracy: 0.6102\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 500: 0.6677797258044441--- Accuracy: 0.6104\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 600: 0.6675810710385842--- Accuracy: 0.61\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 700: 0.6677424706508679--- Accuracy: 0.61\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 800: 0.6677302837959349--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 900: 0.6680588518616465--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 1000: 0.6681723868985169--- Accuracy: 0.6094\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 1100: 0.6684204680027547--- Accuracy: 0.6096\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 1200: 0.6676817102973144--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 1300: 0.66789251251611--- Accuracy: 0.6094\n",
      "Accuracy in test set: 0.6048\n",
      "Error epoch 1400: 0.6677395087847597--- Accuracy: 0.6102\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 1500: 0.6679539553447957--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.6052\n",
      "Error epoch 1600: 0.6677892258715635--- Accuracy: 0.6078\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 1700: 0.6673704271395674--- Accuracy: 0.6088\n",
      "Accuracy in test set: 0.6044\n",
      "Error epoch 1800: 0.6674687279853784--- Accuracy: 0.6094\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 1900: 0.6680737886682837--- Accuracy: 0.6096\n",
      "Accuracy in test set: 0.6072\n",
      "Error epoch 2000: 0.6666343906409856--- Accuracy: 0.6094\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 2100: 0.6670760096457292--- Accuracy: 0.6098\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 2200: 0.6671891323455754--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.608\n",
      "Error epoch 2300: 0.6671628699606968--- Accuracy: 0.6088\n",
      "Accuracy in test set: 0.609\n",
      "Error epoch 2400: 0.6672652025672658--- Accuracy: 0.6102\n",
      "Accuracy in test set: 0.6094\n",
      "Error epoch 2500: 0.6673311346795741--- Accuracy: 0.6088\n",
      "Accuracy in test set: 0.609\n",
      "Error epoch 2600: 0.6672782623345872--- Accuracy: 0.6092\n",
      "Accuracy in test set: 0.6088\n",
      "Error epoch 2700: 0.6676682745194956--- Accuracy: 0.6096\n",
      "Accuracy in test set: 0.6054\n",
      "Error epoch 2800: 0.6677613525383206--- Accuracy: 0.6086\n",
      "Accuracy in test set: 0.6058\n",
      "Error epoch 2900: 0.6679725201753356--- Accuracy: 0.6082\n",
      "Accuracy in test set: 0.6056\n",
      "Error epoch 3000: 0.6679983152040829--- Accuracy: 0.6096\n",
      "Accuracy in test set: 0.606\n",
      "Error epoch 3100: 0.6679405340907559--- Accuracy: 0.6106\n",
      "Accuracy in test set: 0.6072\n",
      "Error epoch 3200: 0.6679309807140374--- Accuracy: 0.6104\n",
      "Accuracy in test set: 0.6064\n",
      "Error epoch 3300: 0.6680708178776672--- Accuracy: 0.6106\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 3400: 0.6681530297101742--- Accuracy: 0.6108\n",
      "Accuracy in test set: 0.6066\n",
      "Error epoch 3500: 0.6682005290042153--- Accuracy: 0.61\n",
      "Accuracy in test set: 0.6066\n",
      "Error epoch 3600: 0.6680468049653482--- Accuracy: 0.6102\n",
      "Accuracy in test set: 0.6062\n",
      "Error epoch 3700: 0.6680879467124828--- Accuracy: 0.61\n",
      "Accuracy in test set: 0.606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w9/sqb6btqs30jdv8h_fy7t6wp80000gn/T/ipykernel_19372/3704650830.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentumGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/w9/sqb6btqs30jdv8h_fy7t6wp80000gn/T/ipykernel_19372/1223611286.py\u001b[0m in \u001b[0;36mMomentumGD\u001b[0;34m(self, X, y, x_test, y_test, beta)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mAccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0;31m#Calcular el error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w9/sqb6btqs30jdv8h_fy7t6wp80000gn/T/ipykernel_19372/1223611286.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w9/sqb6btqs30jdv8h_fy7t6wp80000gn/T/ipykernel_19372/1223611286.py\u001b[0m in \u001b[0;36mactivate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m#np.exp - (x - np.max(x, axis = 1, keepdims= True))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;31m#self.output = 1 / (1+ np.exp(-x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_weights = net2.weights\n",
    "trained_biases = net2.biases\n",
    "\n",
    "nr = 5000\n",
    "net2.MomentumGD(X_train[:nr],y_train[:nr],X_test[:nr], y_test[:nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "77f72717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02276468, -0.00950927,  0.04026177,  0.0336648 ], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "# import numpy as np\n",
    "# import tflearn\n",
    "# from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "# from tflearn.layers.estimator import regression\n",
    "# from statistics import median, mean\n",
    "# from collections import Counter\n",
    "\n",
    "LR = 1e-3\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5713b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a287fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 184.6921818181818\n",
      "choice 1:0.508144755844368  choice 0:0.4918552441556319\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "choices = []\n",
    "goal_steps = 200\n",
    "score_requirement = 50\n",
    "for each_game in range(5500):\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    prev_obs = []\n",
    "    env.reset()\n",
    "    for _ in range(goal_steps):\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            net2.forward(prev_obs)\n",
    "            action = np.argmax(net2.activated_layers[-1])\n",
    "\n",
    "        choices.append(action)\n",
    "                \n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        \n",
    "        game_memory.append([new_observation, action])\n",
    "        score+=reward\n",
    "        if done: break\n",
    "\n",
    "    scores.append(score)\n",
    "\n",
    "print('Average Score:',sum(scores)/len(scores))\n",
    "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "print(score_requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc04c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
