{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nnMAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPRQ0Ck3VSXTMfFzzB1oSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malfaroe/NeuralNetworksMae/blob/main/nnMAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU51ooak3Z3z"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65LleTap3cpk"
      },
      "source": [
        "class Network(object):\n",
        "    def __init__(self, sizes, input, output, lr):\n",
        "        self.sizes = sizes\n",
        "        self.input = input\n",
        "        self.output = output\n",
        "        self.weights = [np.random.rand(self.sizes[s + 1], self.sizes[s]) \n",
        "        for s in range(len(self.sizes) - 1)]\n",
        "        self.biases = [np.random.rand(self.sizes[s + 1], 1)\n",
        "         for s in range(len(self.sizes) - 1)]\n",
        "        self.lr = lr\n",
        "\n",
        "  \n",
        "    #Forward pass\n",
        "    def forward(self, x_in):\n",
        "        x = x_in\n",
        "        activations = [x] ###check\n",
        "        for (w,b) in zip(self.weights, self.biases):\n",
        "            x = self.sigmoid(np.dot(w,x) + b)\n",
        "            activations.append(x)\n",
        "        return activations[-1], activations\n",
        "\n",
        "    #Cost function\n",
        "    def mse(self, y_pred, y):\n",
        "        return (np.sum((y_pred - y)**2)/ len(y))\n",
        "\n",
        "    def mse_prime(self, y_pred, y):\n",
        "        return 2 * (y_pred - y) / len(y)\n",
        "\n",
        "\n",
        "    #Activation function\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_prime(self,x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    \n",
        "    def backprop(self, activations, y):\n",
        "        sigmas = []\n",
        "        nabla_W = []\n",
        "        nabla_B = []\n",
        "\n",
        "        #Compute output layer sigma\n",
        "        y_pred = activations[-1]\n",
        "        delta_C = self.mse_prime(y_pred, y)\n",
        "        sigmas.append(np.multiply(delta_C, self.sigmoid_prime(y_pred)))\n",
        "\n",
        "        #Compute the rest of the sigma vector\n",
        "        for i in range(1, len(self.sizes)):\n",
        "            sigma = np.multiply(np.dot(self.weights[-i].T, sigmas[-1]), self.sigmoid_prime(activations[-i-1]))\n",
        "            sigmas.append(sigma)\n",
        "        sigmas = sigmas[::-1] #se invierte\n",
        "        #compute the nabla for w and b\n",
        "        nabla_W = [sigmas[-i] * activations[-i-1].T for i in range(1,len(self.sizes))][::-1]\n",
        "        nabla_B = [s for s in sigmas[1:]]\n",
        "\n",
        "        #Update weights and biases\n",
        "        self.weights = [self.weights[i] - self.lr * nabla_W[i] for i in range(len(self.weights))]\n",
        "        self.biases = [self.biases[i] - self.lr * nabla_B[i] for i in range(len(self.biases))]\n",
        "\n",
        "\n",
        "    \n",
        "    def run(self):\n",
        "        epochs = 500000\n",
        "        for e in range(epochs):\n",
        "            sum_error = 0\n",
        "            for x, y in list(zip(self.input, self.output)):\n",
        "                    y_pred, activations = self.forward(x)\n",
        "                    error = self.mse(y_pred, y)\n",
        "                    sum_error += error\n",
        "                    self.backprop(activations, y)\n",
        "            if e % 10000 == 0 :\n",
        "                print(\"Error epoch {}----------: {}\".format(e, sum_error))\n",
        "\n",
        "\n",
        "\"\"\" Correccion:\n",
        "- El update de weights se hace una vez recorrido todo el dataset. En cada\n",
        "example se genera un nabla. Finalmente se deben promediar todos\n",
        "- Se suman todos los nablas por cada example.Backprop en realidad\n",
        "tiene que return nablaw y nablab (conteniendo las sumas)\n",
        "- Agregar un update de weights y biases: w- 1/len(dataset)*nablaw\n",
        "- \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R4PUpB2r_64"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data  # we only take the first two features.\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "def vectorize(x, y):\n",
        "    #Vectorize x\n",
        "    new_x = []\n",
        "    for row in x:\n",
        "        new_x.append(np.reshape(row, (len(row),1)))\n",
        "    y_vector = []\n",
        "    for i in y:\n",
        "        y_v = np.zeros((3,1))\n",
        "        y_v[i]= 1\n",
        "        y_vector.append(y_v)\n",
        "    return  np.array(new_x), np.array(y_vector)\n",
        "\n",
        "    \n",
        "\n",
        "X, y_output = vectorize(X, y)\n",
        "X.shape\n",
        "y_output.shape\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEoO6ZudsQL4",
        "outputId": "c2d11da3-b9c6-435e-819c-ca6bef8a2ba0"
      },
      "source": [
        "\"\"\" NEXT:\n",
        "- Estructurar modulo de evaluacion (accuracy, rmse, etc)\n",
        "- Poner epochs como input en network\n",
        "- Incorporar trabajo con test set\n",
        "- Incorporar modulo de vectorizacion y preprocessing data (data Loader..)\n",
        "- Evaluar construccion de un modulo Utils\n",
        "- http://numba.pydata.org/\n",
        "Optimize nn: https://www.youtube.com/watch?v=aAYfnllkkn8&ab_channel=UnfoldDataScience\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGGdTU-LtubH"
      },
      "source": [
        "size = [4, 10,  3]\n",
        "nn = Network(sizes = size, input = X,  output = y_output,lr =  0.5)\n",
        "nn.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR78R6z83ijH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}